# analyzer/pcap_analyzer.py
"""
M√≥dulo para an√°lise de arquivos PCAP com LLM

NOTA DE C√ìDIGO:
- Vari√°veis t√©cnicas (src_ip, dst_ip, timestamp) mantidas em ingl√™s (padr√£o RFC/Scapy)
- Vari√°veis de neg√≥cio (resumo, dominios_consultados) em portugu√™s (legibilidade)
- TODO: Padronizar para ingl√™s completo em vers√£o futura para internacionaliza√ß√£o
"""

import math
import os
import sys
import logging
import struct
import csv
from collections import defaultdict
from datetime import datetime

# Configurar o logger
# N√≠vel INFO: logger.info(), N√≠vel AVISO: logger.warning(), N√≠vel ERRO: logger.error()
logger = logging.getLogger(__name__)

# Adicionar path do projeto principal para importar m√≥dulos (APENAS PARA TESTE LOCAL)
# Esta l√≥gica foi movida para o bloco __main__ para n√£o sujar o escopo global
# current_dir = os.path.dirname(os.path.abspath(__file__))
# parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
# sys.path.append(parent_dir)

try:
    from scapy.all import rdpcap, IP, IPv6, TCP, UDP, Raw, DNS, ARP, Ether, conf
    import ollama

    # HARDENING: Prote√ß√£o contra PCAPs maliciosos (RCE)
    # Desabilitar dissectors que podem executar c√≥digo arbitr√°rio
    conf.layers.filter([Ether, IP, IPv6, TCP, UDP, DNS, ARP, Raw])
    
    DEPENDENCIES_OK = True
except ImportError as e:
    logger.critical(f"Erro ao importar depend√™ncias: {e}")
    logger.critical("Certifique-se de que scapy e ollama est√£o instalados")
    DEPENDENCIES_OK = False

# Importa√ß√£o condicional para evitar erro quando executado diretamente
try:
    from .utils import get_ollama_models as get_ollama_models_subprocess
    from .yara_detector import (
        executar_analise_yara_completa,
    )  # INTEGRA√á√ÉO COM M√ìDULO YARA
except ImportError:
    # Fallback quando executado diretamente
    logger.warning(
        "Executando em modo 'standalone'. M√≥dulos .utils e .yara_detector n√£o carregados."
    )

    def get_ollama_models_subprocess():
        return ["llama3", "llama3.1", "qwen2.5"]

    def executar_analise_yara_completa(arquivo_pcap):
        return {
            "status": "erro",
            "relatorio_texto": "‚ùå M√≥dulo YARA n√£o dispon√≠vel (modo standalone)",
        }


################################################################################
# 1. CENTRAL DE CONFIGURA√á√ÉO E INDICADORES DE COMPROMETIMENTO (IOCs)
################################################################################


class Config:
    """
    Central de configura√ß√£o para thresholds e scores
    
    ‚ö†Ô∏è MANUTENIBILIDADE: Configura√ß√µes hardcoded no c√≥digo
    Problema: Alterar thresholds requer editar c√≥digo-fonte e redeploy
    
    TODO: Migrar para arquivo externo (config.yaml ou .env)
    Exemplo:
        config.yaml:
            detection:
              syn_flood_min_packets: 2000
              syn_flood_ack_ratio: 0.02
              port_scan_threshold: 100
            scoring:
              ddos_critical: 30
              botnet_high: 20
    
    Benef√≠cios: Hot-reload, ambientes diferentes (dev/prod), auditoria de mudan√ßas
    """

    # === Thresholds de Detec√ß√£o ===
    # M√∫ltiplas Conex√µes (Botnet)
    BOTNET_CONNECTIONS_LOW = 50
    BOTNET_CONNECTIONS_MEDIUM = 100
    BOTNET_CONNECTIONS_HIGH = 200
    BOTNET_CONNECTIONS_CRITICAL = 500

    # Port Scanning
    PORT_SCAN_LOW = 100
    PORT_SCAN_MEDIUM = 200
    PORT_SCAN_HIGH = 500
    PORT_SCAN_CRITICAL = 1000

    # Flooding
    FLOOD_LOW = 500
    FLOOD_MEDIUM = 1000
    FLOOD_HIGH = 3000
    FLOOD_CRITICAL = 8000

    # DDoS Espec√≠fico -  DETECTAR ATAQUES REAIS
    SYN_FLOOD_MIN_PACKETS = 300       
    SYN_FLOOD_ACK_RATIO = 0.1         
    UDP_FLOOD_THRESHOLD = 1000        
    UDP_FLOOD_DNS_THRESHOLD = 500      
    ICMP_FLOOD_LOW = 500              
    ICMP_FLOOD_HIGH = 2000
    ACK_FLOOD_THRESHOLD = 1000
    ARP_SPOOFING_THRESHOLD = 100       # Pacotes ARP de um mesmo IP
    FRAGMENT_ATTACK_THRESHOLD = 100    # Fragmentos IP para um mesmo alvo
    
    # Anomalias de Tr√°fego
    SPIKE_MULTIPLIER = 10  # Tr√°fego 10x acima da m√©dia √© spike
    BANDWIDTH_THRESHOLD_MBPS = 100  # 100 Mbps √© alto
    CONNECTION_TIMEOUT_SECONDS = 300  # 5 minutos sem atividade
    PACKET_SIZE_ANOMALY_MIN = 64  # Menor que MTU suspeito
    PACKET_SIZE_ANOMALY_MAX = 1500  # Maior que MTU padr√£o

    # Comunica√ß√£o C2
    C2_MIN_ENTROPY = 7.5  # Mais restritivo
    C2_COUNT_LOW = 5
    C2_COUNT_MEDIUM = 10
    C2_COUNT_HIGH = 20

    # Dom√≠nios
    DOMAINS_SUSPICIOUS_COUNT = 3
    DOMAINS_MALICIOUS_COUNT_MEDIUM = 1
    DOMAINS_MALICIOUS_COUNT_HIGH = 5

    # Dom√≠nios Asi√°ticos
    ASIAN_DOMAIN_COUNT = 5

    # === Scores de Risco (de 100) ===
    # O score total √© limitado a 100
    SCORE_DDoS_CRITICAL = 30
    SCORE_DDoS_HIGH = 25
    SCORE_DDoS_MEDIUM = 15

    SCORE_BOTNET_CRITICAL = 25
    SCORE_BOTNET_HIGH = 20
    SCORE_BOTNET_MEDIUM = 15
    SCORE_BOTNET_LOW = 10

    SCORE_PORTSCAN_CRITICAL = 20
    SCORE_PORTSCAN_HIGH = 15
    SCORE_PORTSCAN_MEDIUM = 10
    SCORE_PORTSCAN_LOW = 5

    SCORE_FLOOD_CRITICAL = 15
    SCORE_FLOOD_HIGH = 12
    SCORE_FLOOD_MEDIUM = 8
    SCORE_FLOOD_LOW = 5

    SCORE_C2_HIGH = 20
    SCORE_C2_MEDIUM = 15
    SCORE_C2_LOW = 10
    SCORE_C2_MINIMAL = 5

    SCORE_DOMAINS_MALICIOUS_HIGH = 10
    SCORE_DOMAINS_MALICIOUS_MEDIUM = 8
    SCORE_DOMAINS_SUSPICIOUS = 5

    SCORE_ASIAN_DOMAINS_HIGH = 5
    SCORE_ASIAN_DOMAINS_LOW = 2


################################################################################
# WHITELISTS DE IPs CONHECIDOS (Previne Falsos Positivos Cr√≠ticos)
################################################################################

# CR√çTICO: LLMs locais (llama3, qwen, gemma) N√ÉO t√™m conhecimento atualizado de ASNs
# Eles inventam ASNs, confundem 8.8.8.8 com malware, acham 1.1.1.1 suspeito
# Whitelists previnem falsos positivos em tr√°fego leg√≠timo (YouTube, Netflix, etc)

# ‚ö†Ô∏è LIMITA√á√ÉO CONHECIDA: Whitelists est√°ticas podem gerar falsos negativos
# IPs de nuvem (AWS, Azure, GCP) s√£o reciclados constantemente
# Atacantes podem alugar IPs whitelistados para evas√£o
# TODO: Migrar para consulta DNS reversa (PTR) ou base GeoIP/ASN atualiz√°vel

KNOWN_GOOD_IPS = {
    # Google DNS e servi√ßos
    "8.8.8.8", "8.8.4.4",
    # Cloudflare DNS
    "1.1.1.1", "1.0.0.1",
    # OpenDNS
    "208.67.222.222", "208.67.220.220",
}

# Prefixos de ranges conhecidos (matching parcial para performance)
KNOWN_GOOD_PREFIXES = [
    # Google LLC (AS15169)
    "142.250.", "142.251.", "172.217.", "172.253.", "74.125.", "216.58.",
    # Cloudflare (AS13335)
    "104.16.", "104.17.", "104.18.", "104.19.", "104.20.", "104.21.",
    "104.22.", "104.23.", "104.24.", "104.25.", "104.26.", "104.27.",
    "162.158.", "172.64.", "172.65.", "172.66.", "172.67.", "173.245.",
    # Amazon AWS (AS16509, AS14618)
    "52.", "54.", "18.", "3.", "13.", "34.", "35.",
    # Microsoft Azure (AS8075)
    "40.", "13.", "20.", "23.", "51.", "52.", "104.",
    # Akamai (AS20940)
    "23.0.", "23.1.", "23.2.", "23.32.", "23.33.", "23.34.", "23.35.",
    "23.192.", "23.193.", "23.194.", "23.195.", "23.196.",
    "104.64.", "104.65.", "104.66.", "104.67.", "104.68.", "104.69.",
    # Fastly CDN (AS54113)
    "151.101.",
]

# Dom√≠nios conhecidos leg√≠timos
KNOWN_GOOD_DOMAINS = [
    # Big Tech
    "google.com", "youtube.com", "googleapis.com", "gstatic.com", "ggpht.com",
    "facebook.com", "fbcdn.net", "whatsapp.com", "instagram.com",
    "microsoft.com", "windows.com", "live.com", "outlook.com", "office.com",
    "apple.com", "icloud.com", "cdn-apple.com",
    "amazon.com", "amazonaws.com", "cloudfront.net",
    # CDNs
    "cloudflare.com", "akamai.com", "akamaihd.net", "fastly.net",
    # Streaming
    "netflix.com", "nflxvideo.net", "nflxext.com", "nflximg.com",
    "spotify.com", "twitch.tv", "ttvnw.net",
    # Outros
    "wikipedia.org", "wikimedia.org",
]

def is_known_good_ip(ip):
    """Verifica se IP pertence a provedor conhecido leg√≠timo"""
    if ip in KNOWN_GOOD_IPS:
        return True
    for prefix in KNOWN_GOOD_PREFIXES:
        if ip.startswith(prefix):
            return True
    return False

def is_known_good_domain(domain):
    """Verifica se dom√≠nio √© de provedor conhecido leg√≠timo"""
    domain_lower = domain.lower().strip(".")
    for good_domain in KNOWN_GOOD_DOMAINS:
        if domain_lower == good_domain or domain_lower.endswith("." + good_domain):
            return True
    return False

def is_local_ip(ip):
    """Verifica se IP √© local/privado (RFC1918, IPv6 link-local, loopback)"""
    if not ip:
        return False
    
    # IPv4 privado (RFC1918)
    if ip.startswith("10.") or ip.startswith("192.168.") or ip.startswith("172."):
        # 172.16.0.0 - 172.31.255.255
        if ip.startswith("172."):
            try:
                second_octet = int(ip.split(".")[1])
                if 16 <= second_octet <= 31:
                    return True
            except (ValueError, IndexError):
                pass
        else:
            return True
    
    # Loopback
    if ip.startswith("127.") or ip == "::1":
        return True
    
    # IPv6 link-local (fe80::/10)
    if ip.startswith("fe80:") or ip.startswith("fe80::"):
        return True
    
    # IPv6 ULA (Unique Local Address - fc00::/7)
    if ip.startswith("fc") or ip.startswith("fd"):
        return True
    
    # IPv6 multicast (ff00::/8)
    if ip.startswith("ff"):
        return True
    
    return False


################################################################################
# 2. M√ìDULOS DE HEUR√çSTICA E AN√ÅLISE
################################################################################


def analisar_iocs_e_dominios(dados):
    """
    Coleta dom√≠nios e IPs acessados para an√°lise pela IA
    Separa IPs/dom√≠nios conhecidos (whitelist) de desconhecidos (an√°lise IA)
    """
    
    resultado = {
        # Lista de todos os dom√≠nios DNS vistos
        "dominios_consultados": [],
        # IPs √∫nicos de destino (FILTRADOS: sem IPs conhecidos leg√≠timos)
        "ips_destino_unicos": set(),
        # IPs conhecidos leg√≠timos (para relat√≥rio)
        "ips_legitimos": set(),
        # Dom√≠nios conhecidos leg√≠timos (para relat√≥rio)
        "dominios_legitimos": [],
        # Campos mantidos para compatibilidade
        "dominios_suspeitos": [],
        "malicious_ips": [],
        "malicious_domains": [],
        "suspicious_countries": [],
        "asian_domains": [],
    }

    for pkt in dados:
        dst_ip = pkt.get("dst_ip")
        src_ip = pkt.get("src_ip")
        dns_query = pkt.get("dns_query")
        
        # Coletar dom√≠nios DNS (separar conhecidos de desconhecidos)
        if dns_query:
            query = dns_query.lower().strip('.')
            if query:
                # Verificar se √© dom√≠nio conhecido leg√≠timo
                if is_known_good_domain(query):
                    if query not in resultado["dominios_legitimos"]:
                        resultado["dominios_legitimos"].append(query)
                else:
                    # Dom√≠nio desconhecido - enviar para IA analisar
                    if not any(d["dominio"] == query for d in resultado["dominios_consultados"]):
                        resultado["dominios_consultados"].append({
                            "dominio": query,
                            "src_ip": src_ip,
                            "timestamp": pkt.get("timestamp", 0),
                        })
        
        # Coletar IPs de destino (separar conhecidos de desconhecidos)
        if dst_ip and dst_ip not in ["Raw Data", "Unknown"]:
            if is_known_good_ip(dst_ip):
                resultado["ips_legitimos"].add(dst_ip)
            else:
                resultado["ips_destino_unicos"].add(dst_ip)
        
        # Verificar IP de origem tamb√©m
        if src_ip and src_ip not in ["Raw Data", "Unknown"]:
            if is_known_good_ip(src_ip):
                resultado["ips_legitimos"].add(src_ip)

    # Converter sets para listas para serializa√ß√£o
    resultado["ips_destino_unicos"] = list(resultado["ips_destino_unicos"])
    resultado["ips_legitimos"] = list(resultado["ips_legitimos"])
    
    return resultado


def calcular_score_malware(dados, padroes_suspeitos, iocs_e_dominios):
    """Calcula score de probabilidade de malware (0-100) baseado em evid√™ncias e thresholds do Config
    *** ATUALIZADO: Usa iocs_e_dominios unificado ***
    """
    score = 0
    evidencias = []

    # SCORING POR CATEGORIA
    cfg = Config  # Atalho para a classe de configura√ß√£o

    # 0. PRIORIDADE: Ataques DDoS (Score M√°ximo: SCORE_DDoS_CRITICAL)
    if padroes_suspeitos.get("ddos_attacks"):
        for attack_key, attack_info in padroes_suspeitos["ddos_attacks"].items():
            if isinstance(attack_info, dict):
                severity = attack_info.get("severity", "M√âDIO")
                attack_type = attack_info.get("type", "DDoS")

                if severity == "CR√çTICO":
                    score += cfg.SCORE_DDoS_CRITICAL
                    evidencias.append(
                        f"CR√çTICO: {attack_type} detectado - "
                        f"Alvo: {attack_info.get('target')}:{attack_info.get('port')} "
                        f"({attack_info.get('num_attackers', 'N/A')} atacantes)"
                    )
                elif severity == "ALTO":
                    score += cfg.SCORE_DDoS_HIGH
                    evidencias.append(
                        f"ALTO: {attack_type} - "
                        f"Atacante: {attack_info.get('attacker')} ‚Üí "
                        f"V√≠tima: {attack_info.get('target')}:{attack_info.get('port')} "
                        f"({attack_info.get('syn_packets', 0)} pacotes SYN)"
                    )
                elif severity == "M√âDIO":
                    score += cfg.SCORE_DDoS_MEDIUM
                    evidencias.append(
                        f"M√âDIO: {attack_type} - "
                        f"{attack_info.get('attacker')} ‚Üí {attack_info.get('target')}"
                    )

    # 1. M√∫ltiplas conex√µes externas (Score M√°ximo: SCORE_BOTNET_CRITICAL)
    if padroes_suspeitos.get("hosts_com_multiplas_conexoes"):
        for host, count in padroes_suspeitos.get("hosts_com_multiplas_conexoes", {}).items():
            if count > cfg.BOTNET_CONNECTIONS_CRITICAL:
                score += cfg.SCORE_BOTNET_CRITICAL
                evidencias.append(
                    f"CR√çTICO: {host} conectou a {count} destinos externos (botnet massiva)"
                )
            elif count > cfg.BOTNET_CONNECTIONS_HIGH:
                score += cfg.SCORE_BOTNET_HIGH
                evidencias.append(
                    f"ALTO: {host} conectou a {count} destinos externos (botnet)"
                )
            elif count > cfg.BOTNET_CONNECTIONS_MEDIUM:
                score += cfg.SCORE_BOTNET_MEDIUM
                evidencias.append(f"ALTO: {host} conectou a {count} destinos externos")
            elif count > cfg.BOTNET_CONNECTIONS_LOW:
                score += cfg.SCORE_BOTNET_LOW
                evidencias.append(f"M√âDIO: {host} conectou a {count} destinos externos")

    # 2. Port scanning (Score M√°ximo: SCORE_PORTSCAN_CRITICAL)
    if padroes_suspeitos.get("port_scanning"):
        for scan, ports in padroes_suspeitos.get("port_scanning", {}).items():
            if ports > cfg.PORT_SCAN_CRITICAL:
                score += cfg.SCORE_PORTSCAN_CRITICAL
                evidencias.append(f"CR√çTICO: Port scan massivo {scan} ({ports} portas)")
            elif ports > cfg.PORT_SCAN_HIGH:
                score += cfg.SCORE_PORTSCAN_HIGH
                evidencias.append(f"ALTO: Port scan extenso {scan} ({ports} portas)")
            elif ports > cfg.PORT_SCAN_MEDIUM:
                score += cfg.SCORE_PORTSCAN_MEDIUM
                evidencias.append(f"M√âDIO: Port scan {scan} ({ports} portas)")
            elif ports > cfg.PORT_SCAN_LOW:
                score += cfg.SCORE_PORTSCAN_LOW
                evidencias.append(f"BAIXO: Port scan {scan} ({ports} portas)")

    # 3. Comunica√ß√£o C2 (Score M√°ximo: SCORE_C2_HIGH)
    if padroes_suspeitos.get("comunicacao_c2"):
        high_entropy_count = len(
            [
                c
                for c in padroes_suspeitos.get("comunicacao_c2", [])
                if c["entropy"] > cfg.C2_MIN_ENTROPY
            ]
        )
        total_c2 = len(padroes_suspeitos.get("comunicacao_c2", []))

        if high_entropy_count > cfg.C2_COUNT_HIGH:
            score += cfg.SCORE_C2_HIGH
            evidencias.append(
                f"CR√çTICO: {high_entropy_count} conex√µes C2 de alta entropia"
            )
        elif high_entropy_count > cfg.C2_COUNT_MEDIUM:
            score += cfg.SCORE_C2_MEDIUM
            evidencias.append(f"ALTO: {high_entropy_count} conex√µes C2 suspeitas")
        elif total_c2 > cfg.C2_COUNT_LOW:
            score += cfg.SCORE_C2_LOW
            evidencias.append(
                f"M√âDIO: {total_c2} comunica√ß√µes criptografadas suspeitas"
            )
        else:
            score += cfg.SCORE_C2_MINIMAL
            evidencias.append(f"BAIXO: Comunica√ß√£o criptografada detectada")

    # 5. Dom√≠nios maliciosos (Score M√°ximo: SCORE_DOMAINS_MALICIOUS_HIGH)
    if iocs_e_dominios.get("dominios_suspeitos"):
        malicious_domains = len(
            [
                d
                for d in iocs_e_dominios.get("dominios_suspeitos", [])
                if d["tipo"] == "dominio_malicioso_conhecido"
            ]
        )
        total_suspicious = len(iocs_e_dominios.get("dominios_suspeitos", []))

        if malicious_domains > cfg.DOMAINS_MALICIOUS_COUNT_HIGH:
            score += cfg.SCORE_DOMAINS_MALICIOUS_HIGH
            evidencias.append(
                f"CR√çTICO: {malicious_domains} dom√≠nios maliciosos conhecidos"
            )
        elif malicious_domains >= cfg.DOMAINS_MALICIOUS_COUNT_MEDIUM:
            score += cfg.SCORE_DOMAINS_MALICIOUS_MEDIUM
            evidencias.append(
                f"ALTO: {malicious_domains} dom√≠nios maliciosos conhecidos"
            )
        elif total_suspicious > cfg.DOMAINS_SUSPICIOUS_COUNT:
            score += cfg.SCORE_DOMAINS_SUSPICIOUS
            evidencias.append(f"M√âDIO: {total_suspicious} dom√≠nios suspeitos")

    # 6. Dom√≠nios asi√°ticos suspeitos (Score M√°ximo: SCORE_ASIAN_DOMAINS_HIGH)
    if iocs_e_dominios.get("asian_domains"):
        asian_count = len(set(iocs_e_dominios.get("asian_domains", [])))
        if asian_count > cfg.ASIAN_DOMAIN_COUNT:
            score += cfg.SCORE_ASIAN_DOMAINS_HIGH
            evidencias.append(f"M√âDIO: {asian_count} dom√≠nios asi√°ticos suspeitos")
        else:
            score += cfg.SCORE_ASIAN_DOMAINS_LOW
            evidencias.append(f"BAIXO: {asian_count} dom√≠nios asi√°ticos detectados")

    # 8. Anomalias de tr√°fego (Score M√°ximo: 10)
    if padroes_suspeitos.get("anomalias_trafego"):
        anomaly_count = len(padroes_suspeitos["anomalias_trafego"])
        if anomaly_count > 5:
            score += 10
            evidencias.append(f"M√âDIO: {anomaly_count} anomalias de tr√°fego detectadas")
        else:
            score += 5
            evidencias.append(f"BAIXO: {anomaly_count} anomalias de tr√°fego")

    # 9. Vazamento de dados (Score M√°ximo: 15)
    if padroes_suspeitos.get("data_leakage"):
        total_leaked = sum(leak["total_bytes"] for leak in padroes_suspeitos.get("data_leakage", []))
        mb_leaked = total_leaked / (1024 * 1024)
        if mb_leaked > 100:  # > 100 MB
            score += 15
            evidencias.append(f"CR√çTICO: {mb_leaked:.2f} MB enviados externamente")
        elif mb_leaked > 50:
            score += 10
            evidencias.append(f"ALTO: {mb_leaked:.2f} MB enviados externamente")
        else:
            score += 5
            evidencias.append(f"M√âDIO: {mb_leaked:.2f} MB enviados externamente")

    # 10. Conex√µes suspeitas (Score M√°ximo: 8)
    if padroes_suspeitos.get("conexoes_suspeitas"):
        susp_conn_count = len(padroes_suspeitos.get("conexoes_suspeitas", []))
        if susp_conn_count > 10:
            score += 8
            evidencias.append(f"M√âDIO: {susp_conn_count} conex√µes a portas n√£o-padr√£o")
        else:
            score += 4
            evidencias.append(f"BAIXO: {susp_conn_count} conex√µes suspeitas")

    # Limitar score m√°ximo
    score = min(score, 100)

    return {"score": score, "nivel": get_risk_level(score), "evidencias": evidencias}


def get_risk_level(score):
    """Converte score em n√≠vel de risco"""
    if score >= 80:
        return "CR√çTICO"
    elif score >= 60:
        return "ALTO"
    elif score >= 40:
        return "M√âDIO"
    elif score >= 20:
        return "BAIXO"
    else:
        return "M√çNIMO"


def analisar_comportamento_temporal(dados):
    """
    Analisa padr√µes temporais suspeitos e comportamentos de beaconing.
    *** CORRIGIDO: Agora usa timestamps reais em vez de √≠ndices. ***
    """
    comportamentos = {
        "beaconing_intervals": [],
        "burst_patterns": [],
        "periodic_communication": [],
        "time_based_anomalies": [],
    }

    # Agrupar por conex√£o (src_ip, dst_ip, dst_port)
    conexoes = defaultdict(list)
    for pkt in dados:
        # Validar timestamp > 0 para evitar falsos positivos com timestamps inv√°lidos
        timestamp = pkt.get("timestamp", 0)
        if pkt["src_ip"] and pkt["dst_ip"] and timestamp > 0:
            key = (pkt["src_ip"], pkt["dst_ip"], pkt["dst_port"])
            conexoes[key].append(timestamp)

    # Detectar beaconing (comunica√ß√£o peri√≥dica caracter√≠stica de malware)
    for conexao, timestamps in conexoes.items():
        # Validar e filtrar timestamps v√°lidos
        timestamps = [t for t in timestamps if isinstance(t, (int, float)) and t > 0]
        
        if len(timestamps) >= 5:  # Pelo menos 5 comunica√ß√µes
            # Ordenar timestamps para garantir
            timestamps.sort()
            intervalos = [
                timestamps[i + 1] - timestamps[i] for i in range(len(timestamps) - 1)
            ]

            # Verificar se intervalos s√£o consistentes (indicativo de beaconing)
            if len(intervalos) > 0:
                media_intervalo = sum(intervalos) / len(intervalos)
                # Calcular vari√¢ncia. Baixa vari√¢ncia = intervalos consistentes
                variancia = sum((x - media_intervalo) ** 2 for x in intervalos) / len(
                    intervalos
                )

                # Se a vari√¢ncia for baixa (< 1.0s) e houver pacotes suficientes
                if variancia < 1.0 and len(timestamps) >= 10:
                    comportamentos["beaconing_intervals"].append(
                        {
                            "conexao": f"{conexao[0]}‚Üí{conexao[1]}:{conexao[2]}",
                            "intervalo_medio_s": round(media_intervalo, 2),
                            "variancia_s2": round(variancia, 2),
                            "count": len(timestamps),
                            "suspeita": "beaconing_malware_consistente",
                        }
                    )

            # Detectar burst patterns (rajadas de comunica√ß√£o)
            if len(timestamps) > 50:
                duracao = timestamps[-1] - timestamps[0] if len(timestamps) > 1 else 0.1
                # Se a dura√ß√£o for muito curta (ex: > 50 pacotes em < 2 segundos)
                if duracao < 2.0:
                    comportamentos["burst_patterns"].append(
                        {
                            "conexao": f"{conexao[0]}‚Üí{conexao[1]}:{conexao[2]}",
                            "total_packets": len(timestamps),
                            "duracao_s": round(duracao, 2),
                            "suspeita": "burst_ddos_or_data_exfiltration",
                        }
                    )

    return comportamentos




def calcular_entropia(data):
    """Calcula a entropia de dados bin√°rios"""
    if not data:
        return 0.0
    
    data_len = len(data)
    if data_len == 0:
        return 0.0

    ocorrencias = {}
    for byte in data:
        ocorrencias[byte] = ocorrencias.get(byte, 0) + 1

    entropia = 0
    for count in ocorrencias.values():
        p_x = count / data_len
        entropia -= p_x * math.log2(p_x)

    return entropia


################################################################################
# 3. PROCESSADOR DE PACOTES (PARSER)
################################################################################


def processar_csv(arquivo_csv):
    """
    Processa arquivo CSV exportado de ferramentas de rede (Wireshark, tcpdump, etc)
    Formatos suportados:
    - Wireshark: Export Packet Dissections > As CSV
    - Colunas m√≠nimas: No., Time, Source, Destination, Protocol, Length, Info
    - Colunas opcionais: Source Port, Destination Port, TCP Flags
    
    Retorna lista de dicts no mesmo formato de processar_pcap()
    """
    resumo = []
    
    try:
        with open(arquivo_csv, 'r', encoding='utf-8', errors='ignore') as f:
            # Detectar delimitador (v√≠rgula, ponto-e-v√≠rgula, tab)
            sample = f.read(1024)
            f.seek(0)
            
            delimiter = ','
            if sample.count(';') > sample.count(','):
                delimiter = ';'
            elif sample.count('\t') > sample.count(','):
                delimiter = '\t'
            
            reader = csv.DictReader(f, delimiter=delimiter)
            
            # Mapear nomes de colunas comuns (case-insensitive)
            for row in reader:
                # Normalizar keys para lowercase
                row_lower = {k.lower().strip(): v for k, v in row.items()}
                
                # Extrair campos principais (tentar varia√ß√µes de nomes)
                timestamp = 0.0
                for time_key in ['time', 'timestamp', 'time_relative', 'frame.time_relative']:
                    if time_key in row_lower and row_lower[time_key]:
                        try:
                            timestamp = float(row_lower[time_key])
                            break
                        except (ValueError, TypeError):
                            continue
                
                src_ip = None
                for src_key in ['source', 'src', 'ip.src', 'source address']:
                    if src_key in row_lower and row_lower[src_key]:
                        src_ip = row_lower[src_key].strip()
                        break
                
                dst_ip = None
                for dst_key in ['destination', 'dst', 'ip.dst', 'destination address']:
                    if dst_key in row_lower and row_lower[dst_key]:
                        dst_ip = row_lower[dst_key].strip()
                        break
                
                protocol = None
                for proto_key in ['protocol', 'proto', '_ws.col.protocol']:
                    if proto_key in row_lower and row_lower[proto_key]:
                        protocol = row_lower[proto_key].strip().upper()
                        break
                
                length = 0
                for len_key in ['length', 'len', 'frame.len', 'packet length']:
                    if len_key in row_lower and row_lower[len_key]:
                        try:
                            length = int(row_lower[len_key])
                            break
                        except (ValueError, TypeError):
                            continue
                
                # Portas (opcional)
                src_port = None
                for sport_key in ['source port', 'src port', 'tcp.srcport', 'udp.srcport']:
                    if sport_key in row_lower and row_lower[sport_key]:
                        try:
                            src_port = int(row_lower[sport_key])
                            break
                        except (ValueError, TypeError):
                            continue
                
                dst_port = None
                for dport_key in ['destination port', 'dst port', 'tcp.dstport', 'udp.dstport']:
                    if dport_key in row_lower and row_lower[dport_key]:
                        try:
                            dst_port = int(row_lower[dport_key])
                            break
                        except (ValueError, TypeError):
                            continue
                
                # Info/DNS query
                dns_query = None
                info = row_lower.get('info', row_lower.get('_ws.col.info', ''))
                if info and 'dns' in protocol.lower() if protocol else False:
                    # Extrair query do campo Info
                    if 'query' in info.lower():
                        dns_query = info.strip()
                
                # TCP Flags (opcional)
                tcp_flags = None
                for flag_key in ['tcp flags', 'tcp.flags', 'flags']:
                    if flag_key in row_lower and row_lower[flag_key]:
                        tcp_flags = row_lower[flag_key].strip()
                        break
                
                # Converter protocolo para n√∫mero (aproximado)
                proto_num = None
                if protocol:
                    proto_map = {
                        'TCP': 6,
                        'UDP': 17,
                        'ICMP': 1,
                        'ICMPv6': 58,
                        'ARP': 'ARP',
                        'DNS': 17,  # DNS usa UDP
                        'HTTP': 6,  # HTTP usa TCP
                        'HTTPS': 6,
                        'TLS': 6,
                        'SSL': 6,
                    }
                    proto_num = proto_map.get(protocol, protocol)
                
                # Criar registro no formato padr√£o
                if src_ip and dst_ip:  # M√≠nimo necess√°rio
                    info_dict = {
                        'timestamp': timestamp,
                        'src_ip': src_ip,
                        'dst_ip': dst_ip,
                        'protocol': proto_num or 'Unknown',
                        'ip_version': 4 if '.' in src_ip else (6 if ':' in src_ip else 'Unknown'),
                        'length': length,
                        'entropy': None,  # CSV n√£o tem payload para calcular entropia
                        'src_port': src_port,
                        'dst_port': dst_port,
                        'tcp_flags': tcp_flags,
                        'dns_query': dns_query,
                    }
                    resumo.append(info_dict)
        
        logger.info(f"‚úÖ CSV processado: {len(resumo)} registros v√°lidos")
        return resumo
        
    except Exception as e:
        logger.error(f"Erro ao processar CSV: {e}")
        raise Exception(f"Erro ao processar arquivo CSV: {str(e)}")


def processar_pcap(arquivo_pcap):
    """
    Processa arquivo PCAP em streaming (evita OOM em arquivos grandes)
    Usa PcapReader para ler pacote por pacote sem carregar tudo na RAM
    """
    from scapy.utils import PcapReader
    
    try:
        resumo = []
        pacotes_sem_ip = 0

        with PcapReader(arquivo_pcap) as pcap_reader:
            for pkt in pcap_reader:
                info = None
                try:
                    timestamp = float(pkt.time) if hasattr(pkt, 'time') else 0.0
                except (ValueError, TypeError, AttributeError):
                    timestamp = 0.0

                # Processar pacotes IP
                if IP in pkt:
                    info = {
                        "timestamp": timestamp,
                        "src_ip": pkt[IP].src,
                        "dst_ip": pkt[IP].dst,
                        "protocol": pkt[IP].proto,
                        "ip_version": 4,
                        "length": len(pkt),
                        "entropy": None,
                        "src_port": None,
                        "dst_port": None,
                        "tcp_flags": None,
                        "dns_query": None,
                    }

                # Processar pacotes IPv6
                elif IPv6 in pkt:
                    info = {
                        "timestamp": timestamp,
                        "src_ip": pkt[IPv6].src,
                        "dst_ip": pkt[IPv6].dst,
                        "protocol": pkt[IPv6].nh,  # Next Header
                        "ip_version": 6,
                        "length": len(pkt),
                        "entropy": None,
                        "src_port": None,
                        "dst_port": None,
                        "tcp_flags": None,
                        "dns_query": None,
                    }

                # Processar pacotes ARP (coletar MAC para detec√ß√£o de spoofing)
                elif ARP in pkt:
                    info = {
                        "timestamp": timestamp,
                        "src_ip": pkt[ARP].psrc,
                        "dst_ip": pkt[ARP].pdst,
                        "protocol": "ARP",
                        "ip_version": "ARP",
                        "length": len(pkt),
                        "entropy": None,
                        "src_port": None,
                        "dst_port": None,
                        "tcp_flags": None,
                        "dns_query": None,
                        "arp_op": pkt[ARP].op,
                        "src_mac": pkt[ARP].hwsrc if hasattr(pkt[ARP], 'hwsrc') else None,
                        "dst_mac": pkt[ARP].hwdst if hasattr(pkt[ARP], 'hwdst') else None,
                    }

                # Pacotes n√£o-IP (Raw/Unknown): ignorar
                # Se Scapy n√£o parseou, provavelmente √© camada 2 ou corrupto
                else:
                    pacotes_sem_ip += 1
                    info = None

                # Se encontrou um tipo de pacote suportado
                if info:
                    # Processar TCP/UDP
                    if TCP in pkt:
                        info["tcp_flags"] = str(pkt[TCP].flags)
                        info["src_port"] = pkt[TCP].sport
                        info["dst_port"] = pkt[TCP].dport
                    elif UDP in pkt:
                        info["src_port"] = pkt[UDP].sport
                        info["dst_port"] = pkt[UDP].dport
                        if DNS in pkt:
                            try:
                                if pkt[DNS].qd:
                                    info["dns_query"] = pkt[DNS].qd.qname.decode("utf-8")
                            except (AttributeError, UnicodeDecodeError, IndexError):
                                pass

                    # Calcular entropia do payload
                    # üöÄ OTIMIZA√á√ÉO: Amostragem para evitar c√°lculo em milh√µes de pacotes
                    # Problema: PCAP de 5GB ‚Üí milh√µes de c√°lculos de entropia ‚Üí horas
                    # Solu√ß√£o: Amostrar apenas 1 em cada 100 pacotes + limitar payload a 1KB
                    if Raw in pkt and len(resumo) % 100 == 0:  # Amostragem 1%
                        try:
                            payload = bytes(pkt[Raw].load)
                            # Limitar a primeiros 1024 bytes (evita processar payloads gigantes)
                            if len(payload) > 1024:
                                payload = payload[:1024]
                            info["entropy"] = round(calcular_entropia(payload), 4)
                        except Exception:
                            info["entropy"] = None

                    resumo.append(info)
                else:
                    pacotes_sem_ip += 1

        if not resumo:
            raise Exception(
                f"Nenhum pacote IP/IPv6/ARP encontrado no arquivo PCAP. "
                f"Pacotes processados: {pacotes_sem_ip + len(resumo)}, "
                f"Pacotes n√£o-IP: {pacotes_sem_ip}. "
                f"Este arquivo pode conter protocolos n√£o suportados ou dados corrompidos."
            )

        logger.info(f"‚úÖ PCAP processado: {len(resumo)} pacotes v√°lidos, {pacotes_sem_ip} n√£o-IP ignorados")
        return resumo

    except Exception as e:
        logger.error(f"Erro fatal ao processar PCAP: {str(e)}")
        raise Exception(f"Erro ao processar PCAP: {str(e)}")


def analisar_padroes_botnet(dados, ips_origem, ips_destino):
    """
    Analisa padr√µes espec√≠ficos de botnet e malware
    *** OTIMIZADO: Loop √∫nico consolidado com valida√ß√£o consistente ***
    
    ‚ö†Ô∏è REFATORA√á√ÉO NECESS√ÅRIA (God Method Anti-Pattern):
    Esta fun√ß√£o mistura m√∫ltiplas responsabilidades (DDoS, port scan, C2, vazamento de dados)
    em um √∫nico loop gigante, tornando testes unit√°rios e manuten√ß√£o dif√≠ceis.
    
    TODO: Separar em m√≥dulos especializados:
    - detect_ddos_patterns()
    - detect_port_scans()
    - detect_c2_communication()
    - detect_data_exfiltration()
    - detect_traffic_anomalies()
    """
    padroes = {
        "hosts_com_multiplas_conexoes": {},
        "comunicacao_c2": [],
        "port_scanning": {},
        "ddos_attacks": {},
        "anomalias_trafego": [],
        "conexoes_suspeitas": [],
        "data_leakage": [],
    }

    cfg = Config

    # Inicializar detectores
    # ===================================================================
    # CORRELA√á√ÉO BIDIRECIONAL: Rastreia handshake TCP completo (SYN + SYN-ACK)
    # Chave: (IP_CLIENTE, IP_SERVIDOR, PORTA_SERVIDOR)
    # SYN (ida): Cliente ‚Üí Servidor => chave = (src, dst, dst_port)
    # SYN-ACK (volta): Servidor ‚Üí Cliente => INVERTE para chave = (dst, src, src_port)
    # ===================================================================
    tcp_handshakes = defaultdict(lambda: {"syn": 0, "synack": 0, "sources": set()})
    
    # Volume por ALVO (para detectar DDoS distribu√≠do)
    udp_target_volume = defaultdict(lambda: {"count": 0, "sources": set()})
    icmp_target_volume = defaultdict(int)
    ack_flood_target = defaultdict(int)
    fragmented_by_target = defaultdict(int)

    # Contadores auxiliares
    conexoes_por_host = defaultdict(set)
    port_scan_detector = defaultdict(set)
    portas_suspeitas = defaultdict(int)
    uploads = defaultdict(int)
    high_entropy_packets = []
    MAX_ENTROPY_SAMPLES = 1000  # Limite para prevenir OOM em PCAPs grandes
    traffic_by_hour = defaultdict(int)
    invalid_timestamps = 0  # Contador para debug
    protocol_count = defaultdict(int)
    tiny_packets = 0
    jumbo_packets = 0
    arp_table = defaultdict(int)
    arp_ip_to_mac = defaultdict(set)
    
    portas_conhecidas = {20, 21, 22, 23, 25, 53, 80, 110, 143, 443, 465, 587, 993, 995, 3306, 3389, 5432, 8080, 8443}

    # ======== LOOP √öNICO CONSOLIDADO ========
    # üöÄ OTIMIZA√á√ÉO: Adicionar contador para amostrar opera√ß√µes pesadas
    packet_counter = 0
    for pkt in dados:
        packet_counter += 1
        src_ip = pkt.get("src_ip")
        dst_ip = pkt.get("dst_ip")
        src_port = pkt.get("src_port")
        dst_port = pkt.get("dst_port")
        protocol = pkt.get("protocol")
        tcp_flags = pkt.get("tcp_flags")
        length = pkt.get("length", 0)
        entropy = pkt.get("entropy")
        timestamp = pkt.get("timestamp", 0)
        ip_version = pkt.get("ip_version")

        # Valida√ß√£o de IP consistente - Early return para performance
        ip_valid = src_ip and dst_ip and src_ip not in ["Raw Data", "Unknown"] and dst_ip not in ["Raw Data", "Unknown"]
        
        # Early return: ignora pacotes sem IPs v√°lidos (ARP sem IP, raw data)
        if not ip_valid:
            continue
        
        # 1. Hosts com m√∫ltiplas conex√µes
        is_src_internal = src_ip.startswith(("10.", "192.168.", "172."))
        is_dst_external = not dst_ip.startswith(("10.", "192.168.", "172."))
        
        if is_src_internal and is_dst_external:
                conexoes_por_host[src_ip].add(dst_ip)
                uploads[src_ip] += length  # 2. Data leakage tracking
        
        # Ignorar tr√°fego leg√≠timo conhecido (evita falsos positivos)
        if is_known_good_ip(dst_ip) or is_known_good_ip(src_ip):
            continue  # ‚Üê IMPORTANTE: n√£o contar ataques contra Google, Cloudflare, etc.

        # 2. TCP: Correla√ß√£o bidirecional (SYN + SYN-ACK)
        if protocol == 6 and tcp_flags and src_port and dst_port:
            flags_str = str(tcp_flags)
            
            # Cen√°rio 1: Cliente enviando SYN (Ida) - Cliente ‚Üí Servidor
            if "S" in flags_str and "A" not in flags_str:
                # Chave: (Cliente, Servidor, Porta_Servidor)
                key = (src_ip, dst_ip, dst_port)
                tcp_handshakes[key]["syn"] += 1
                tcp_handshakes[key]["sources"].add(src_ip)
                
                # Port scan detection (ignora portas ef√™meras)
                if dst_port < 10000:
                    port_scan_detector[(src_ip, dst_ip)].add(dst_port)
            
            # Cen√°rio 2: Servidor respondendo SYN-ACK (Volta) - Servidor ‚Üí Cliente
            elif "S" in flags_str and "A" in flags_str:
                # INVERS√ÉO DA CHAVE: Servidor √© src agora, mas na chave ele √© dst
                # Chave reversa: (Cliente, Servidor, Porta_Servidor)
                key_reverse = (dst_ip, src_ip, src_port)
                
                # S√≥ contabiliza se j√° vimos o SYN de ida (evita ru√≠do)
                if key_reverse in tcp_handshakes:
                    tcp_handshakes[key_reverse]["synack"] += 1

            # ACK Flood: APENAS ACKs √≥rf√£os (sem SYN pr√©vio)
            # ACKs normais de conex√µes estabelecidas s√£o leg√≠timos
            if "A" in flags_str and "S" not in flags_str and "F" not in flags_str:
                # Verificar se existe handshake estabelecido (SYN foi visto)
                key_forward = (src_ip, dst_ip, dst_port)
                key_reverse = (dst_ip, src_ip, src_port if src_port else 0)
                
                # S√≥ conta como flood se N√ÉO existe SYN anterior (ACK √≥rf√£o)
                if key_forward not in tcp_handshakes and key_reverse not in tcp_handshakes:
                    ack_flood_target[(dst_ip, dst_port)] += 1

        # 3. UDP Flood: agregado por alvo (detecta DDoS distribu√≠do)
        if protocol == 17:  # UDP n√£o requer dst_port (pode ser fragmentado)
            udp_target_volume[dst_ip]["count"] += 1
            if src_ip:  # Adiciona source apenas se v√°lido
                udp_target_volume[dst_ip]["sources"].add(src_ip)

        # 4. ICMP Flood
        if protocol == 1:
            icmp_target_volume[dst_ip] += 1
        
        # 8. ARP Spoofing (CORRIGIDO: detectar conflitos de MAC)
        if ip_version == "ARP" and src_ip:
            arp_table[src_ip] += 1
            # Rastrear m√∫ltiplos MACs para mesmo IP (spoofing)
            src_mac = pkt.get("src_mac")
            if src_mac:
                arp_ip_to_mac[src_ip].add(src_mac)
        
        # 9. Fragmenta√ß√£o IP (conta por ALVO) - Suporta dict e Scapy Packet
        if isinstance(pkt, dict) and pkt.get("fragmented"):
            fragmented_by_target[dst_ip] += 1
        elif hasattr(pkt, "haslayer") and pkt.haslayer(IP):
            ip_layer = pkt[IP]
            is_fragmented = bool(ip_layer.flags & 0x1) or ip_layer.frag > 0
            if is_fragmented:
                fragmented_by_target[dst_ip] += 1
            
        # 12. Conex√µes suspeitas (portas n√£o-padr√£o)
        if dst_port and dst_port not in portas_conhecidas and dst_port < 49152:
            portas_suspeitas[f"{src_ip} ‚Üí {dst_ip}:{dst_port}"] += 1
        
        # 13. Alta entropia (C2) - ignora TLS/HTTPS e IPs conhecidos
        # ‚ö†Ô∏è LIMITA√á√ÉO: Bin√°rios comprimidos (ZIP, JPG, v√≠deos) geram falsos positivos
        if entropy and entropy > cfg.C2_MIN_ENTROPY:
            portas_tls = {443, 8443, 465, 587, 993, 995, 636, 989, 990, 992, 5061, 853}
            eh_tls = dst_port in portas_tls or src_port in portas_tls
            
            # Filtrar: N√ÉO alertar se porta TLS OU IP conhecido
            if not eh_tls and not is_known_good_ip(src_ip) and not is_known_good_ip(dst_ip):
                # Limite: armazena at√© MAX_ENTROPY_SAMPLES (previne OOM)
                if len(high_entropy_packets) < MAX_ENTROPY_SAMPLES:
                    high_entropy_packets.append(pkt)
                # Amostragem ap√≥s limite (reservoir sampling)
                elif packet_counter % 100 == 0:  # 1% dos pacotes ap√≥s limite
                    import random
                    idx = random.randint(0, MAX_ENTROPY_SAMPLES - 1)
                    high_entropy_packets[idx] = pkt
        
        # 14. Tr√°fego por hora
        if timestamp > 0:
            try:
                hour = datetime.fromtimestamp(timestamp).hour
                traffic_by_hour[hour] += 1
            except (ValueError, OSError) as e:
                invalid_timestamps += 1
                if invalid_timestamps <= 5:  # Log primeiros 5 erros
                    logger.warning(f"Timestamp inv√°lido ignorado: {timestamp} - {e}")
        
        # 15. Protocolos incomuns
        if protocol not in [1, 6, 17]:
            protocol_count[protocol] += 1
        
        # 16. Tamanhos an√¥malos
        if length < cfg.PACKET_SIZE_ANOMALY_MIN:
            tiny_packets += 1
        elif length > cfg.PACKET_SIZE_ANOMALY_MAX:
            jumbo_packets += 1
    
    # ======== P√ìS-PROCESSAMENTO: DETEC√á√ÉO FINAL DE DDoS ========
    cfg = Config

    # ===================================================================
    # PROTE√á√ÉO CONTRA FALSOS POSITIVOS EM TR√ÅFEGO NORMAL (OBRIGAT√ìRIO!)
    # ===================================================================
    
    # Calcular dura√ß√£o total do PCAP (em segundos)
    timestamps = [pkt["timestamp"] for pkt in dados if pkt.get("timestamp", 0) > 0]
    if len(timestamps) < 2:
        duracao_segundos = 1
    else:
        duracao_segundos = max(timestamps) - min(timestamps)
        if duracao_segundos < 1:
            duracao_segundos = 1
    
    # Calcular PPS m√©dio
    pps_medio = len(dados) / duracao_segundos
    
    # Regras anti-falso-positivo (se n√£o passar, IGNORA o ataque)
    def is_trafego_normal_legitimo(target_ip, port, syn_count=None, synack_count=None, udp_count=None):
        # 1. IP da v√≠tima √© conhecido (Google, Cloudflare, etc) ‚Üí nunca √© alvo real
        if is_known_good_ip(target_ip):
            return True
        
        # 1b. IP local/privado ‚Üí mas PERMITE se volume muito alto (ataques internos/labs)
        # Deixar cada detector decidir baseado no volume
        
        # 2. PPS muito baixo = n√£o √© flood (independente da porta)
        if pps_medio < 50:  # menos de 50 pacotes/segundo = tr√°fego humano
            return True
        
        # 3. Muitos SYN mas com SYN-ACK alto = navega√ß√£o normal
        # CR√çTICO: S√≥ considera "normal" se RATIO ALTO (>70% resposta)
        if syn_count and synack_count and syn_count > 100:
            ratio = synack_count / max(syn_count, 1)
            if ratio > 0.7:  # mais de 70% dos SYN t√™m resposta ‚Üí navega√ß√£o normal
                return True
        
        return False

    # 1. Analisar SYN Flood - AGREGA√á√ÉO POR ALVO primeiro, depois an√°lise
    syn_flood_by_target = defaultdict(lambda: {"syn": 0, "synack": 0, "sources": set(), "connections": []})
    
    # ETAPA 1: Agregar todas as conex√µes por alvo
    for (attacker, target, port), metrics in tcp_handshakes.items():
        target_key = (target, port)
        syn_flood_by_target[target_key]["syn"] += metrics["syn"]
        syn_flood_by_target[target_key]["synack"] += metrics["synack"]
        syn_flood_by_target[target_key]["sources"].add(attacker)
        syn_flood_by_target[target_key]["connections"].append({
            "attacker": attacker,
            "syns": metrics["syn"],
            "synacks": metrics["synack"]
        })
    
    # ETAPA 2: Analisar volume agregado por alvo
    for (target, port), aggregated in syn_flood_by_target.items():
        total_syns = aggregated["syn"]
        total_synacks = aggregated["synack"]
        num_sources = len(aggregated["sources"])
        
        # Threshold AGREGADO (n√£o por conex√£o individual)
        if total_syns < cfg.SYN_FLOOD_MIN_PACKETS:  # Ex: 300 SYNs TOTAIS
            continue
        
        # Calcular ratio agregado
        ratio = total_synacks / (total_syns + 1)
        
        # Se ratio baixo = servidor n√£o consegue responder = flood
        if ratio < cfg.SYN_FLOOD_ACK_RATIO:  # Ex: <10% resposta
            # PROTE√á√ÉO CONTRA FALSO POSITIVO (mas com exce√ß√£o para volume alto)
            # Se volume muito alto (>1000 SYNs), detecta mesmo se IP local
            if total_syns < 1000 and is_trafego_normal_legitimo(target, port, total_syns, total_synacks):
                continue
            severity = "CR√çTICO" if num_sources >= 5 else "ALTO"
            attack_type = "SYN Flood Distribu√≠do" if num_sources >= 5 else "SYN Flood"
            
            # Para ataques distribu√≠dos, lista principais atacantes
            if num_sources >= 5:
                top_attackers = sorted(
                    aggregated["connections"],
                    key=lambda x: x["syns"],
                    reverse=True
                )[:5]
                attacker_list = ", ".join([a["attacker"] for a in top_attackers])
                attacker_display = f"{num_sources} atacantes (top: {attacker_list})"
            else:
                attacker_display = ", ".join(aggregated["sources"])
            
            padroes["ddos_attacks"][f"{attack_type}_{target}:{port}"] = {
                "type": attack_type,
                "attacker": attacker_display,
                "target": target,
                "port": port,
                "syn_sent": total_syns,
                "ack_received": total_synacks,
                "ratio": f"{ratio:.2f}",
                "num_attackers": num_sources,
                "severity": severity,
            }

    # 2. Analisar UDP Flood (Agregado por alvo)
    for target, data in udp_target_volume.items():
        count = data["count"]
        sources = len(data["sources"])
        
        if count > cfg.UDP_FLOOD_THRESHOLD:
            # PROTE√á√ÉO CONTRA FALSO POSITIVO
            if is_known_good_ip(target):
                continue  # Ignora DNS Google, Cloudflare, etc
            
            # NOVO: Verificar PPS - mas considerar volume absoluto tamb√©m
            udp_pps = count / duracao_segundos
            
            # Regras de detec√ß√£o mais inteligentes:
            # 1. Alto volume absoluto (>5000) = sempre suspeito (MESMO se IP local)
            #    Permite detectar ataques internos/labs
            # 2. PPS moderado/alto (>50) = flood ativo
            # 3. Volume m√©dio + PPS baixo + IP local = pode ser tr√°fego normal
            if count < 5000 and udp_pps < 50:
                # Volume baixo + PPS baixo = provavelmente tr√°fego normal espalhado
                continue
            
            # Ignora IPs locais APENAS se volume baixo (<5000)
            # Se volume alto, detecta mesmo sendo IP local (ataque interno/lab)
            if count < 5000 and is_local_ip(target):
                continue  # Tr√°fego local baixo n√£o √© DDoS
            
            severity = "CR√çTICO" if sources >= 5 else "ALTO"
            attack_type = "UDP Flood Distribu√≠do" if sources >= 5 else "UDP Flood"
            
            padroes["ddos_attacks"][f"UDP_FLOOD ‚Üí {target}"] = {
                "type": attack_type,
                "target": target,
                "packet_count": count,
                "num_attackers": sources,
                "severity": severity,
            }

    # 4. ICMP Flood
    for target_ip, count in icmp_target_volume.items():
        if count > cfg.ICMP_FLOOD_LOW:
            severity = "ALTO" if count > cfg.ICMP_FLOOD_HIGH else "M√âDIO"
            padroes["ddos_attacks"][f"ICMP_FLOOD_{target_ip}"] = {
                "type": "ICMP Flood (Ping Flood)",
                "target": target_ip,
                "icmp_packets": count,
                "severity": severity,
            }

    # ACK Flood (apenas ACKs √≥rf√£os)
    for target_key, count in ack_flood_target.items():
        if count > cfg.ACK_FLOOD_THRESHOLD:
            target_ip, port = target_key
            
            # PROTE√á√ÉO CONTRA FALSO POSITIVO
            if is_trafego_normal_legitimo(target_ip, port):
                continue  # Ignora IPs conhecidos ou PPS baixo
            
            padroes["ddos_attacks"][f"ACK_FLOOD_{target_ip}:{port}"] = {
                "type": "ACK Flood",
                "target": target_ip,
                "port": port,
                "ack_packets": count,
                "severity": "ALTO",
            }

    # 5. Processar Port Scanning
    for (src, dst), ports in port_scan_detector.items():
        if len(ports) > cfg.PORT_SCAN_MEDIUM:  # Ex: 10 portas
            padroes["port_scanning"][f"{src} ‚Üí {dst}"] = {
                "ports_scanned": len(ports),
                "example_ports": list(ports)[:5],
            }
    
    # 6. Identificar IPs envolvidos em ataques (para filtrar falsos positivos)
    ddos_ips = set()
    for attack_info in padroes["ddos_attacks"].values():
        if isinstance(attack_info, dict):
            if attack_info.get("attacker"):
                ddos_ips.add(attack_info["attacker"])
            if attack_info.get("target"):
                ddos_ips.add(attack_info["target"])
    
    # 7. Upload/Exfiltra√ß√£o (excluir IPs de DDoS)
    for src, bytes_sent in uploads.items():
        if src not in ddos_ips:
            mb_sent = bytes_sent / (1024 * 1024)
            if mb_sent > 50:  # 50MB
                padroes["data_leakage"].append({
                    "src": src,
                    "mb_sent": f"{mb_sent:.2f} MB",
                    "tipo": "Alto volume de upload",
                })
    
    # 8. Processar hosts com m√∫ltiplas conex√µes (excluir IPs de DDoS)
    for host, destinos in conexoes_por_host.items():
        if host not in ddos_ips and len(destinos) > cfg.BOTNET_CONNECTIONS_LOW:
            padroes["hosts_com_multiplas_conexoes"][host] = len(destinos)
    
    # ARP Spoofing (mantido - funciona bem)
    for src_ip, mac_addresses in arp_ip_to_mac.items():
        if len(mac_addresses) > 1:
            padroes["ddos_attacks"][f"ARP_SPOOFING_MAC_CONFLICT: {src_ip}"] = {
                "type": "ARP Spoofing (Conflito de MAC)",
                "ip": src_ip,
                "mac_addresses": list(mac_addresses),
                "num_macs": len(mac_addresses),
                "severity": "CR√çTICO",
            }
    
    for src_ip, count in arp_table.items():
        if count > cfg.ARP_SPOOFING_THRESHOLD and len(arp_ip_to_mac.get(src_ip, set())) <= 1:
            padroes["ddos_attacks"][f"ARP_FLOODING: {src_ip}"] = {
                "type": "ARP Flooding (Alto Volume)",
                "source": src_ip,
                "arp_packets": count,
                "num_attackers": 1,
                "severity": "M√âDIO",
            }
    
    # Fragmenta√ß√£o IP por alvo
    for target_ip, count in fragmented_by_target.items():
        if count > cfg.FRAGMENT_ATTACK_THRESHOLD:
            padroes["ddos_attacks"][f"FRAGMENTATION_ATTACK_{target_ip}"] = {
                "type": "Ataque de Fragmenta√ß√£o IP",
                "target": target_ip,
                "small_packets": count,
                "severity": "M√âDIO",
            }
    
    # Alta entropia (mantido - funciona bem)
    for pkt in high_entropy_packets:
        src_ip = pkt["src_ip"]
        dst_ip = pkt["dst_ip"]
        dst_port = pkt.get("dst_port")
        src_port = pkt.get("src_port")
        
        # Ignorar IPs de DDoS e portas HTTPS/TLS conhecidas
        portas_tls = {443, 8443, 465, 587, 993, 995, 636, 989, 990, 992, 5061}
        eh_porta_tls = dst_port in portas_tls or src_port in portas_tls
        
        if src_ip not in ddos_ips and dst_ip not in ddos_ips and not eh_porta_tls:
            # Alta entropia em porta n√£o-HTTPS = suspeito
            padroes["comunicacao_c2"].append({
                "src": src_ip,
                "dst": dst_ip,
                "port": dst_port or src_port or "desconhecido",
                "entropy": pkt["entropy"],
            })
    
    # Processar conex√µes suspeitas
    for conexao, count in portas_suspeitas.items():
        if count > 200:
            padroes["conexoes_suspeitas"].append({
                "conexao": conexao,
                "count": count,
                "tipo": "porta_nao_padrao_alta_frequencia"
            })
    
    # Processar data leakage
    for src_ip, total_bytes in uploads.items():
        if total_bytes > 10 * 1024 * 1024:
            padroes["data_leakage"].append({
                "src_ip": src_ip,
                "total_bytes": total_bytes,
                "tipo": "upload_massivo_externo"
            })
    
    # Processar tr√°fego por hora
    if traffic_by_hour:
        avg_traffic = sum(traffic_by_hour.values()) / max(len(traffic_by_hour), 1)
        for hour, count in traffic_by_hour.items():
            if count > avg_traffic * cfg.SPIKE_MULTIPLIER and hour in range(0, 6):
                padroes["anomalias_trafego"].append({
                    "hora": hour,
                    "pacotes": count,
                    "media": int(avg_traffic),
                    "tipo": "spike_horario_incomum"
                })
    
    # Processar protocolos incomuns
    for protocol, count in protocol_count.items():
        if count > 100:
            padroes["anomalias_trafego"].append({
                "protocolo": protocol,
                "pacotes": count,
                "tipo": "protocolo_incomum"
            })
    
    # Processar tamanhos an√¥malos
    # üîç REMOVIDO: Pacotes pequenos (<64 bytes) s√£o NORMAIS em TCP (ACKs, handshake)
    # Causa falsos positivos massivos - ACKs t√™m ~54-66 bytes
    # if tiny_packets > 1000:
    #     padroes["anomalias_trafego"].append({
    #         "tipo": "pacotes_muito_pequenos",
    #         "count": tiny_packets,
    #         "tamanho": f"< {cfg.PACKET_SIZE_ANOMALY_MIN} bytes"
    #     })
    
    if jumbo_packets > 100:
        padroes["anomalias_trafego"].append({
            "tipo": "pacotes_jumbo",
            "count": jumbo_packets,
            "tamanho": f"> {cfg.PACKET_SIZE_ANOMALY_MAX} bytes"
        })

    return padroes


def formatar_dados_para_analise(dados, padroes_suspeitos, iocs_e_dominios):
    """Formata dados dos pacotes para an√°lise pelo LLM
    *** OTIMIZADO: Recebe padr√µes j√° calculados para evitar dupla execu√ß√£o ***
    """
    total_pacotes = len(dados)
    ips_origem = set(pkt["src_ip"] for pkt in dados if pkt["src_ip"])
    ips_destino = set(pkt["dst_ip"] for pkt in dados if pkt["dst_ip"])
    protocolos = defaultdict(int)
    portas_destino = defaultdict(int)
    entropias_altas = []
    tipos_ip = {"IPv4": 0, "IPv6": 0, "ARP": 0, "Raw": 0}

    for pkt in dados:
        ip_ver = pkt.get("ip_version", "Raw")
        if ip_ver in tipos_ip:
            tipos_ip[ip_ver] += 1

        protocolos[pkt["protocol"]] += 1

        if pkt["dst_port"]:
            portas_destino[pkt["dst_port"]] += 1

        if (
            pkt["entropy"] and pkt["entropy"] > 6.0
        ):  # Manter 6.0 para logging, 7.5 para scoring
            entropias_altas.append(pkt)

    resumo = f"""
RESUMO DA AN√ÅLISE DE REDE:

ESTAT√çSTICAS GERAIS:
- Total de pacotes: {total_pacotes}
- IPv4: {tipos_ip["IPv4"]} | IPv6: {tipos_ip["IPv6"]} | ARP: {tipos_ip["ARP"]} | Raw: {tipos_ip["Raw"]}
- IPs de origem √∫nicos: {len(ips_origem)}
- IPs de destino √∫nicos: {len(ips_destino)}

PROTOCOLOS DETECTADOS:
"""
    for proto, count in sorted(protocolos.items(), key=lambda x: x[1], reverse=True):
        proto_name = {6: "TCP", 17: "UDP", 1: "ICMP"}.get(proto, f"Protocolo {proto}")
        resumo += f"- {proto_name}: {count} pacotes\n"

    resumo += "\nPORTAS MAIS ACESSADAS:\n"
    for porta, count in sorted(
        portas_destino.items(), key=lambda x: x[1], reverse=True
    )[:10]:
        porta_name = get_port_service(porta)
        resumo += f"- Porta {porta} ({porta_name}): {count} pacotes\n"

    if entropias_altas:
        resumo += f"\nPACOTES COM ALTA ENTROPIA (>6.0): {len(entropias_altas)}\n"
        for pkt in entropias_altas[:5]:
            resumo += f"- {pkt['src_ip']} ‚Üí {pkt['dst_ip']}:{pkt['dst_port']} (entropia: {pkt['entropy']})\n"

    resumo += "\nüîç PADR√ïES DE TR√ÅFEGO DETECTADOS (Para an√°lise contextual pela IA):\n"

    # DEBUG CR√çTICO: Verificar se ataques DDoS foram detectados
    print(f"\n{'='*80}")
    print(f"üîç [CR√çTICO] padroes_suspeitos['ddos_attacks'] = {padroes_suspeitos.get('ddos_attacks')}")
    print(f"üîç [CR√çTICO] N√∫mero de ataques: {len(padroes_suspeitos.get('ddos_attacks', {}))}")
    print(f"{'='*80}\n")

    # SEMPRE adicionar se√ß√£o de ataques (mesmo que vazia) para clareza do LLM
    resumo += "\n" + "="*80 + "\n"
    resumo += "üö® ATAQUES CONFIRMADOS PELO MOTOR HEUR√çSTICO:\n"
    resumo += "="*80 + "\n"
    
    if padroes_suspeitos.get("ddos_attacks"):
        for attack_key, attack_info in padroes_suspeitos["ddos_attacks"].items():
            if isinstance(attack_info, dict):
                resumo += f"- {attack_info.get('type', 'Ataque')}: "
                
                # Atacante ‚Üí Alvo:Porta (se houver)
                if attack_info.get("attacker"):
                    resumo += f"{attack_info['attacker']} ‚Üí "
                
                resumo += f"{attack_info.get('target')}"
                if attack_info.get("port") and not attack_info.get("num_targets"):
                    resumo += f":{attack_info['port']}"
                resumo += " "
                
                # M√©tricas detalhadas
                if attack_info.get("syn_sent"):
                    resumo += f"(SYN: {attack_info['syn_sent']}, ACK: {attack_info.get('ack_received', 0)}, Ratio: {attack_info.get('ratio', 'N/A')})"
                elif attack_info.get("total_syn_packets"):
                    resumo += f"(Total SYN: {attack_info['total_syn_packets']})"
                elif attack_info.get("packet_count"):
                    resumo += f"(Pacotes: {attack_info['packet_count']})"
                elif attack_info.get("icmp_packets"):
                    resumo += f"(ICMP: {attack_info['icmp_packets']})"
                
                # N√∫mero de atacantes (se distribu√≠do)
                if attack_info.get("num_attackers") and attack_info["num_attackers"] > 1:
                    resumo += f" [üéØ {attack_info['num_attackers']} atacantes]"
                
                resumo += f" - Severidade: {attack_info.get('severity', 'DESCONHECIDA')}\n"
    else:
        resumo += "‚úÖ NENHUM ATAQUE DETECTADO\n"
        resumo += "\n"
        resumo += "O motor heur√≠stico analisou o tr√°fego e n√£o identificou:\n"
        resumo += "- SYN Flood (ratio de resposta normal)\n"
        resumo += "- UDP Flood (volume dentro dos limites)\n"
        resumo += "- ICMP Flood (pings normais)\n"
        resumo += "- ACK Flood (ACKs leg√≠timos)\n"
        resumo += "- DDoS Distribu√≠do (sem m√∫ltiplos atacantes coordenados)\n"
        resumo += "- Port Scan massivo (conex√µes normais)\n"
    
    resumo += "="*80 + "\n"
    resumo += "FIM DA SE√á√ÉO DE ATAQUES\n"
    resumo += "="*80 + "\n"

    if padroes_suspeitos.get("hosts_com_multiplas_conexoes"):
        resumo += "\nüîó HOSTS COM M√öLTIPLAS CONEX√ïES:\n"
        for host, count in padroes_suspeitos.get("hosts_com_multiplas_conexoes", {}).items():
            resumo += f"- {host} conectou-se a {count} destinos externos distintos\n"

    if padroes_suspeitos.get("port_scanning"):
        resumo += "\nüîç TESTES DE PORTAS:\n"
        for scan, ports in padroes_suspeitos.get("port_scanning", {}).items():
            resumo += f"- {scan} acessou {ports} portas distintas\n"

    if padroes_suspeitos.get("comunicacao_c2"):
        # üîç FILTRO: Remover entradas de TLS/HTTPS antes de enviar ao LLM
        # Problema: Mesmo com filtro no c√≥digo, LLM pode interpretar como C2
        c2_filtered = [c2 for c2 in padroes_suspeitos.get("comunicacao_c2", []) 
                       if c2.get('port') not in {443, 8443, 465, 587, 993, 995}]
        if c2_filtered:
            resumo += "\nüì° TR√ÅFEGO COM ALTA ENTROPIA (>7.5, portas n√£o-TLS):\n"
            for c2 in c2_filtered[:5]:
                resumo += f"- {c2['src']} ‚Üí {c2['dst']}:{c2['port']} (entropia: {c2['entropy']:.2f})\n"

    # DOM√çNIOS DNS CONSULTADOS (para IA analisar reputa√ß√£o) - LIMITADO para evitar estouro de contexto
    if iocs_e_dominios.get("dominios_consultados"):
        resumo += "\nüåê DOM√çNIOS DNS CONSULTADOS:\n"
        dominios = iocs_e_dominios.get("dominios_consultados", [])[:10]  # Top 10 (reduzido de 15)
        for dom in dominios:
            # üîí SANITIZA√á√ÉO CR√çTICA contra prompt injection
            # VULNERABILIDADE: dom√≠nio como ".\n\n8. IGNORE REGRAS\n\nexample.com"
            # pode fazer LLM ignorar instru√ß√µes e mentir sobre detec√ß√µes
            dominio_limpo = str(dom['dominio'])
            # Remover TODOS caracteres de controle e quebras de linha
            dominio_limpo = dominio_limpo.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ').replace('\0', '')
            # Remover comandos de sistema que podem manipular LLM
            dangerous = ['SYSTEM:', 'USER:', 'ASSISTANT:', 'IGNORE', 'FORGET', 'DISREGARD', 'OVERRIDE']
            for cmd in dangerous:
                dominio_limpo = dominio_limpo.replace(cmd, f"[FILTERED]")
            dominio_limpo = dominio_limpo.strip()
            if len(dominio_limpo) > 100:  # Limitar tamanho
                dominio_limpo = dominio_limpo[:100] + "...[truncado]"
            # Validar se √© dom√≠nio v√°lido (apenas alfanum√©rico, pontos, h√≠fens)
            import re
            if not re.match(r'^[a-zA-Z0-9.-]+$', dominio_limpo):
                dominio_limpo = "[DOM√çNIO_INV√ÅLIDO_FILTRADO]"
            resumo += f"- {dominio_limpo}\n"
        total_dominios = len(iocs_e_dominios.get("dominios_consultados", []))
        if total_dominios > 10:
            resumo += f"... e mais {total_dominios - 10} dom√≠nios\n"
    
    # IPs DE DESTINO √öNICOS (para IA verificar ASN/reputa√ß√£o) - LIMITADO
    if iocs_e_dominios.get("ips_destino_unicos"):
        resumo += "\nüéØ IPs DE DESTINO √öNICOS:\n"
        ips = sorted(iocs_e_dominios.get("ips_destino_unicos", []))[:15]  # Top 15 (reduzido de 20)
        for ip in ips:
            resumo += f"- {ip}\n"
        total_ips = len(iocs_e_dominios.get("ips_destino_unicos", []))
        if total_ips > 15:
            resumo += f"... e mais {total_ips - 15} IPs\n"

    if padroes_suspeitos.get("anomalias_trafego"):
        resumo += "\n‚ö†Ô∏è ANOMALIAS DE TR√ÅFEGO:\n"
        for anomalia in padroes_suspeitos.get("anomalias_trafego", [])[:5]:
            resumo += f"- {anomalia.get('tipo', 'anomalia')}: {anomalia}\n"

    if padroes_suspeitos.get("conexoes_suspeitas"):
        resumo += "\nüîå CONEX√ïES SUSPEITAS:\n"
        for conexao in padroes_suspeitos.get("conexoes_suspeitas", [])[:5]:
            resumo += f"- {conexao['conexao']}: {conexao['count']} pacotes (porta n√£o-padr√£o)\n"

    if padroes_suspeitos.get("data_leakage"):
        resumo += "\nüì§ POSS√çVEL VAZAMENTO DE DADOS:\n"
        for leak in padroes_suspeitos.get("data_leakage", [])[:5]:
            mb = leak['total_bytes'] / (1024 * 1024)
            resumo += f"- {leak['src_ip']}: {mb:.2f} MB enviados externamente\n"

    return resumo


def get_port_service(porta):
    """Retorna o servi√ßo conhecido para uma porta"""
    servicos = {
        20: "FTP-DATA",
        21: "FTP",
        22: "SSH",
        23: "Telnet",
        25: "SMTP",
        53: "DNS",
        67: "DHCP",
        68: "DHCP",
        80: "HTTP",
        110: "POP3",
        135: "RPC",
        137: "NetBIOS",
        138: "NetBIOS",
        139: "NetBIOS",
        143: "IMAP",
        161: "SNMP",
        162: "SNMP-Trap",
        389: "LDAP",
        443: "HTTPS",
        445: "SMB",
        465: "SMTPS",
        514: "Syslog",
        587: "SMTP-MSA",
        636: "LDAPS",
        993: "IMAPS",
        995: "POP3S",
        1433: "SQL Server",
        1521: "Oracle DB",
        3306: "MySQL",
        3389: "RDP",
        5432: "PostgreSQL",
        5900: "VNC",
        6379: "Redis",
        8080: "HTTP-Alt",
        8443: "HTTPS-Alt",
        9200: "Elasticsearch",
        27017: "MongoDB",
    }
    return servicos.get(porta, "Desconhecido")


################################################################################
# 4. INTERA√á√ÉO COM O LLM (OLLAMA)
################################################################################


def analisar_com_llm_hibrido(
    dados_formatados, relatorio_yara, modelo="llama3", host=None, port=None
):
    """An√°lise h√≠brida: LLM para comportamento + YARA como evid√™ncia complementar"""
    
    # PROTE√á√ÉO CONTRA ESTOURO DE CONTEXTO (context window overflow)
    # Limite: 6000 caracteres (~1500 tokens) para dados, deixando espa√ßo para instru√ß√µes e resposta
    MAX_DATA_SIZE = 6000
    
    # ‚ö†Ô∏è TRUNCAMENTO INTELIGENTE: Priorizar se√ß√µes cr√≠ticas
    # Se precisar truncar, remover se√ß√µes menos cr√≠ticas primeiro:
    # 1. Manter: ESTAT√çSTICAS, PADR√ïES DE ATAQUE (DDoS), HOSTS COM M√öLTIPLAS CONEX√ïES
    # 2. Reduzir: Dom√≠nios DNS (j√° limitado a 10), IPs √∫nicos (j√° limitado a 15)
    # 3. Remover: Portas menos acessadas, entropias altas (se necess√°rio)
    # TODO: Implementar truncamento por prioridade em vez de corte cego
    
    if len(dados_formatados) > MAX_DATA_SIZE:
        dados_truncados = dados_formatados[:MAX_DATA_SIZE]
        # Encontrar √∫ltima linha completa
        last_newline = dados_truncados.rfind('\n')
        if last_newline > 0:
            dados_truncados = dados_truncados[:last_newline]
        dados_formatados = dados_truncados + f"\n\n‚ö†Ô∏è [DADOS TRUNCADOS - Total excedeu {MAX_DATA_SIZE} caracteres para evitar estouro de contexto]\n‚ö†Ô∏è Se informa√ß√µes cr√≠ticas estiverem faltando, reduza o tamanho do PCAP ou ajuste MAX_DATA_SIZE"
    
    if len(relatorio_yara) > MAX_DATA_SIZE:
        yara_truncado = relatorio_yara[:MAX_DATA_SIZE]
        last_newline = yara_truncado.rfind('\n')
        if last_newline > 0:
            yara_truncado = yara_truncado[:last_newline]
        relatorio_yara = yara_truncado + f"\n\n‚ö†Ô∏è [RELAT√ìRIO TRUNCADO]"

    # üîí SANITIZA√á√ÉO SELETIVA contra Prompt Injection
    # IMPORTANTE: N√ÉO remover \n dos dados_formatados (quebra a estrutura do prompt)
    # Sanitiza√ß√£o j√° foi feita em formatar_dados_para_analise() nos dom√≠nios DNS
    # Aqui apenas garantimos que n√£o h√° comandos perigosos no YARA report
    def sanitize_yara_only(text):
        """Sanitiza apenas YARA report, preservando formata√ß√£o dos dados"""
        if not text:
            return ""
        # Remover comandos perigosos mas PRESERVAR quebras de linha
        dangerous_keywords = ['SYSTEM:', 'USER:', 'ASSISTANT:', 'IGNORE', 'FORGET', 'DISREGARD']
        for keyword in dangerous_keywords:
            text = text.replace(keyword, f"[FILTERED:{keyword[:3]}]")
        return text
    
    # Aplicar sanitiza√ß√£o APENAS no YARA (n√£o nos dados formatados!)
    # dados_formatados j√° tem sanitiza√ß√£o nos dom√≠nios DNS
    relatorio_yara = sanitize_yara_only(relatorio_yara)
    
    prompt = f"""
DADOS DE TR√ÅFEGO:
{dados_formatados}

RELAT√ìRIO YARA:
{relatorio_yara}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
INSTRU√á√ïES DE AN√ÅLISE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üö® IMPORTANTE: A AN√ÅLISE MATEM√ÅTICA J√Å FOI FEITA
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Os ataques listados na se√ß√£o "üö® ATAQUES CONFIRMADOS PELO MOTOR HEUR√çSTICO" 
foram detectados por algoritmos de correla√ß√£o bidirecional e an√°lise estat√≠stica.

 Procure os ataques e de sua opini√£o no caso de n√£o haver dados da heuristica.

Se houver ataques confirmados acima:
‚úÖ ACEITE-OS COMO FATOS (n√£o questione os n√∫meros)
‚úÖ EXPLIQUE o impacto de cada ataque
‚úÖ RECOMENDE a√ß√µes de mitiga√ß√£o espec√≠ficas

N√ÉO tente "descobrir" ataques analisando estat√≠sticas gerais.
N√ÉO confunda diferentes categorias de tr√°fego:
- "üö® ATAQUES CONFIRMADOS" = Ataques DDoS reais (aceite como fato)
- "üîó M√öLTIPLAS CONEX√ïES" = Comportamento de botnet/scanner (n√£o √© DDoS)
- "üîç TESTES DE PORTAS" = Port scanning (n√£o √© flood)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üö® REGRAS DE AN√ÅLISE:
1. Porta >30000 no IP INTERNO (192.168.x.x) = porta ef√™mera do cliente (NORMAL)
2. Cliente interno ‚Üí Provedor externo porta 443 = Navega√ß√£o HTTPS (NORMAL)
3. Alta entropia em porta 443/8443 = TLS/SSL leg√≠timo (N√ÉO √© C2 automaticamente)
4. IPs filtrados pela whitelist (Google, Cloudflare, AWS) = tr√°fego leg√≠timo

‚ö†Ô∏è NOTA: N√£o tente identificar ASNs ou provedores - use apenas os IPs como est√£o.
O sistema j√° filtrou IPs conhecidos. IPs restantes s√£o desconhecidos e requerem investiga√ß√£o.

‚ö†Ô∏è ATEN√á√ÉO ESPECIAL:
- Se houver se√ß√£o "üìä ALTO VOLUME DE PACOTES" nos dados acima, VOC√ä DEVE INCLUIR ISSO NA SUA AN√ÅLISE
- Se houver ataques DDoS detectados (SYN Flood, UDP Flood, etc), MENCIONE-OS na se√ß√£o 5 (PADR√ïES DE ATAQUE)
- Use os N√öMEROS EXATOS que aparecem nos dados (ex: "2000 SYN packets", n√£o "muitos pacotes")

PROCESSO DE AN√ÅLISE OBRIGAT√ìRIO:

ETAPA 1 - AN√ÅLISE DE IPs:
‚ö†Ô∏è O sistema j√° filtrou IPs conhecidos (Google, Cloudflare, AWS, Azure, Akamai).
Os IPs listados na se√ß√£o "üéØ IPs DE DESTINO √öNICOS" s√£o desconhecidos e requerem investiga√ß√£o.

Para cada IP desconhecido:
- Verifique se h√° volume anormal (muitos pacotes)
- Verifique se h√° portas suspeitas (<1024 ou >49152)
- Verifique se est√° associado a padr√µes de ataque (DDoS, port scan)

N√ÉO tente identificar provedores ou ASNs - isso causa informa√ß√µes incorretas.

ETAPA 2 - AN√ÅLISE DE ATAQUES CONFIRMADOS:
üîç PROCURE ESTA SE√á√ÉO NOS DADOS ACIMA:

================================================================================
üö® ATAQUES CONFIRMADOS PELO MOTOR HEUR√çSTICO:
================================================================================

A se√ß√£o acima ter√° UMA DAS DUAS OP√á√ïES:

OP√á√ÉO A - ATAQUES DETECTADOS:
- SYN Flood: 192.168.1.100 ‚Üí 192.168.1.1:80 (SYN: 5000, ACK: 50, Ratio: 0.01) - Severidade: CR√çTICO
- UDP Flood: 203.0.113.10 (Pacotes: 10000) [üéØ 5 atacantes] - Severidade: CR√çTICO
[etc...]

OP√á√ÉO B - NENHUM ATAQUE:
‚úÖ NENHUM ATAQUE DETECTADO
O motor heur√≠stico analisou o tr√°fego e n√£o identificou:
- SYN Flood (ratio de resposta normal)
- UDP Flood (volume dentro dos limites)
[etc...]

SE ENCONTRAR OP√á√ÉO A (ATAQUES DETECTADOS):
‚úÖ ACEITE como VERDADEIROS (matem√°tica j√° validada)
‚úÖ EXPLIQUE o impacto de cada ataque
‚úÖ RECOMENDE mitiga√ß√£o espec√≠fica
‚úÖ Use os n√∫meros EXATOS fornecidos
‚úÖ Classifique risco baseado na severidade dos ataques

SE ENCONTRAR OP√á√ÉO B (NENHUM ATAQUE):
‚úÖ Escreva "Nenhum ataque confirmado pelo motor heur√≠stico"
‚úÖ Classifique risco baseado em outros indicadores:
   - M√∫ltiplas conex√µes = poss√≠vel botnet/scanner (M√âDIO)
   - Port scan = reconhecimento (M√âDIO/BAIXO)
   - Tr√°fego normal para servi√ßos conhecidos = BAIXO/NORMAL
‚ùå N√ÉO invente ataques DDoS se n√£o estiverem na se√ß√£o de ataques confirmados

CONTEXTO PARA CLASSIFICA√á√ÉO DE RISCO:
- Se houver ataques com severidade CR√çTICO ‚Üí Risco CR√çTICO
- Se houver ataques com severidade ALTO ‚Üí Risco ALTO
- Se nenhum ataque + tr√°fego normal ‚Üí Risco BAIXO/NORMAL
- Cliente ‚Üí Google/Cloudflare/AWS porta 443 = Navega√ß√£o NORMAL
- Pacotes jumbo em HTTPS = Streaming/download NORMAL

ETAPA 3 - CONCLUS√ÉO FINAL:
- Se houver ATAQUES CONFIRMADOS ‚Üí LISTE-OS e EXPLIQUE o impacto
- Se 90%+ dos IPs s√£o Google/CDN/ISP = RISCO PODE SER BAIXO (mas ataques confirmados s√£o CR√çTICOS)
- Se h√° IPs desconhecidos com portas estranhas = Investigar apenas estes

FORMATO DE RESPOSTA (8 se√ß√µes obrigat√≥rias):

1. CLASSIFICA√á√ÉO DE RISCO: [Cr√≠tico/Alto/M√©dio/Baixo/Normal]
   Baseie-se PRIMEIRAMENTE nos ataques confirmados:
   - Se houver ataques com severidade "CR√çTICO" ‚Üí RISCO CR√çTICO
   - Se houver ataques com severidade "ALTO" ‚Üí RISCO ALTO
   - Se n√£o houver ataques confirmados ‚Üí Analise outros indicadores

2. CORRELA√á√ÉO YARA-TR√ÅFEGO: [resultado ou "nenhuma detec√ß√£o"]

3. AMEA√áAS IDENTIFICADAS:
   SE HOUVER "‚úÖ NENHUM ATAQUE DETECTADO":
   - Escreva: "Nenhum ataque confirmado pelo motor heur√≠stico"
   - Mencione outros indicadores (se houver): port scan, m√∫ltiplas conex√µes, etc.
   
   SE HOUVER ATAQUES LISTADOS:
   - Liste TODOS os ataques com m√©tricas
   - Exemplo: "SYN Flood: 192.168.1.100 ‚Üí 192.168.1.1:80 (SYN: 5000, Ratio: 0.01) - CR√çTICO"

4. HOSTS COMPROMETIDOS:
   SE HOUVER "‚úÖ NENHUM ATAQUE DETECTADO":
   - Escreva: "N√£o identificado - nenhum ataque confirmado"
   
   SE HOUVER ATAQUES LISTADOS:
   - V√≠timas: IPs que aparecem como "target"
   - Atacantes: IPs que aparecem como "attacker"

5. PADR√ïES DE ATAQUE:
   SE HOUVER "‚úÖ NENHUM ATAQUE DETECTADO":
   - Escreva: "Nenhum padr√£o de ataque DDoS detectado pelo motor heur√≠stico"
   - Explique: "O sistema analisou correla√ß√£o TCP bidirecional, volumes UDP/ICMP/ACK,
     e n√£o encontrou anomalias que indiquem SYN Flood, UDP Flood, DDoS distribu√≠do,
     ou outros ataques volum√©tricos."
   - Mencione outros indicadores se relevantes (port scan, m√∫ltiplas conex√µes)
   
   SE HOUVER ATAQUES LISTADOS:
   Para cada ataque confirmado, EXPLIQUE:
   - O que √© o ataque (ex: SYN Flood = esgotar recursos TCP do servidor)
   - Por que os n√∫meros indicam ataque (ex: Ratio 0.01 = 99% dos SYNs sem resposta)
   - Qual o impacto (ex: Servidor pode ficar indispon√≠vel)
   
   Exemplo:
   ```
   - SYN Flood: 192.168.1.100 ‚Üí 192.168.1.1:80
     M√©tricas: SYN: 5000, ACK: 50, Ratio: 0.01
     An√°lise: Taxa de resposta de apenas 1% indica flood
     Impacto: Servi√ßo web pode estar indispon√≠vel
   ```
   
   üö´ N√ÉO invente ataques que n√£o est√£o na se√ß√£o "üö® ATAQUES CONFIRMADOS"!
   üö´ N√ÉO transforme "m√∫ltiplas conex√µes" em ataques DDoS!
   
6. A√á√ïES IMEDIATAS:
   SE HOUVER ATAQUES CONFIRMADOS:
   - Comandos espec√≠ficos para bloquear IPs atacantes
   - Ativar rate limiting nas portas afetadas
   
   SE NENHUM ATAQUE:
   - "Nenhuma a√ß√£o imediata necess√°ria - tr√°fego normal"

7. INVESTIGA√á√ÉO FORENSE:
   SE HOUVER ATAQUES CONFIRMADOS:
   - Passos numerados para investigar origem, dura√ß√£o, danos
   
   SE NENHUM ATAQUE:
   - "Nenhuma investiga√ß√£o forense necess√°ria para ataques DDoS"

8. REMEDIA√á√ÉO:
   SE HOUVER ATAQUES CONFIRMADOS:
   - Imediato: Bloquear atacantes, ativar DDoS protection
   - Longo prazo: WAF, rate limiting, redund√¢ncia
   
   SE NENHUM ATAQUE:
   - "Nenhuma remedia√ß√£o necess√°ria - tr√°fego normal"
"""

    try:
        # Configurar cliente Ollama com host/port espec√≠fico (thread-safe)
        # N√£o usar os.environ para evitar polui√ß√£o global em ambientes multithread
        client_options = {}
        if host and port:
            client_options['host'] = f"{host}:{port}"
        elif host:
            client_options['host'] = host
        
        # Criar cliente com configura√ß√£o expl√≠cita ou usar padr√£o
        if client_options:
            cliente = ollama.Client(**client_options)
            resposta = cliente.chat(
                model=modelo, messages=[{"role": "user", "content": prompt}]
            )
        else:
            # Usar cliente padr√£o
            resposta = ollama.chat(
                model=modelo, messages=[{"role": "user", "content": prompt}]
            )
        return resposta["message"]["content"]
    except Exception as e:
        logger.error(f"Erro na an√°lise LLM h√≠brida: {str(e)}")
        return f"Erro na an√°lise LLM h√≠brida: {str(e)}"


# FUN√á√ÉO analisar_com_llm (antiga) REMOVIDA.


def get_available_models():
    """Retorna lista de modelos LLM dispon√≠veis"""
    try:
        models_response = ollama.list()
        models = []
        if isinstance(models_response, dict) and "models" in models_response:
            iterable = models_response["models"]
        elif isinstance(models_response, list):
            iterable = models_response
        else:
            iterable = []

        for model in iterable:
            if isinstance(model, dict):
                name = model.get("name", model.get("model", "unknown"))
            else:
                name = str(model)
            models.append(name)

        if models:
            return models
        return get_ollama_models_subprocess()
    except Exception:
        return get_ollama_models_subprocess()


def get_ollama_status(host=None, port=None):
    """Verifica se o Ollama est√° acess√≠vel e retorna um resumo simples."""
    try:
        if host:
            os.environ.setdefault("OLLAMA_HOST", host)
        if port:
            os.environ.setdefault("OLLAMA_PORT", str(port))

        try:
            resp = ollama.list()
        except Exception:
            resp = None

        if resp:
            if isinstance(resp, dict) and "models" in resp:
                models = resp["models"] or []
            elif isinstance(resp, list):
                models = resp
            else:
                models = []

            count = sum(1 for m in models if m)

            if count == 0:
                parsed = get_ollama_models_subprocess()
                return {"ok": True, "models": len(parsed)}
            return {"ok": True, "models": count}
        else:
            parsed = get_ollama_models_subprocess()
            return {"ok": True, "models": len(parsed)}
    except Exception as e:
        return {"ok": False, "error": str(e)}


################################################################################
# 5. ORQUESTRADOR PRINCIPAL
################################################################################


def analyze_pcap_with_llm(arquivo_pcap, modelo="llama3", host=None, port=None, analysis_mode="full"):
    """
    Fun√ß√£o principal para an√°lise completa de PCAP/CSV com LLM + YARA (h√≠brida)
    *** ATUALIZADO: Suporte para CSV + Modos de an√°lise configur√°veis ***
    
    Formatos suportados:
    - .pcap, .pcapng: An√°lise completa com YARA
    - .csv: An√°lise comportamental (sem YARA, pois n√£o h√° payload)
    
    Modos de an√°lise:
    - 'full': An√°lise completa (YARA + LLM + Heur√≠sticas) - PADR√ÉO
    - 'llm_heuristics': LLM + Heur√≠sticas (sem YARA)
    - 'llm_yara': LLM + YARA (sem detec√ß√µes heur√≠sticas)
    - 'llm_only': Apenas LLM com dados b√°sicos de pacotes
    - 'yara_only': Apenas an√°lise YARA (sem LLM)
    """
    try:
        # Detectar tipo de arquivo
        arquivo_lower = arquivo_pcap.lower()
        is_csv = arquivo_lower.endswith('.csv')
        
        logger.info(
            f"[MAIN] üöÄ Iniciando an√°lise de: {arquivo_pcap} (Tipo: {'CSV' if is_csv else 'PCAP'}, Modo: {analysis_mode.upper()})"
        )

        # 1. AN√ÅLISE COMPORTAMENTAL (para LLM)
        logger.info("[MAIN] üìä Processando pacotes para an√°lise comportamental...")
        
        if is_csv:
            dados_pacotes = processar_csv(arquivo_pcap)
        else:
            dados_pacotes = processar_pcap(arquivo_pcap)

        if not dados_pacotes:
            raise Exception("Nenhum pacote IP encontrado no arquivo")

        # Determinar quais componentes executar baseado no modo
        run_heuristics = analysis_mode in ['full', 'llm_heuristics']
        run_yara = analysis_mode in ['full', 'llm_yara', 'yara_only'] and not is_csv
        run_llm = analysis_mode in ['full', 'llm_heuristics', 'llm_yara', 'llm_only']
        
        # Inicializar vari√°veis padr√£o
        padroes_suspeitos = {}
        iocs_e_dominios = {}
        scoring_result = {"score": 0, "nivel_risco": "M√çNIMO", "evidencias": []}
        comportamento_temporal = {}
        
        # FASE 2: An√°lises especializadas (apenas se heur√≠sticas ativadas)
        if run_heuristics:
            logger.info("üîç Iniciando an√°lise heur√≠stica especializada...")
            ips_origem = set(pkt["src_ip"] for pkt in dados_pacotes if pkt["src_ip"])
            ips_destino = set(pkt["dst_ip"] for pkt in dados_pacotes if pkt["dst_ip"])

            padroes_suspeitos = analisar_padroes_botnet(
                dados_pacotes, ips_origem, ips_destino
            )
            iocs_e_dominios = analisar_iocs_e_dominios(dados_pacotes)

            # FASE 3: Sistema de scoring avan√ßado
            logger.info("üìä Calculando score de malware...")
            scoring_result = calcular_score_malware(
                dados_pacotes, padroes_suspeitos, iocs_e_dominios
            )

            # FASE 5: An√°lise comportamental temporal
            logger.info("‚è±Ô∏è Analisando comportamento temporal (com timestamps reais)...")
            comportamento_temporal = analisar_comportamento_temporal(dados_pacotes)
        else:
            logger.info("‚è≠Ô∏è Modo '{analysis_mode}': Pulando an√°lises heur√≠sticas")

        # FASE 6: Formatar dados para an√°lise LLM (usando padr√µes j√° calculados ou vazios)
        if run_llm:
            dados_formatados = formatar_dados_para_analise(dados_pacotes, padroes_suspeitos, iocs_e_dominios)
        else:
            dados_formatados = "An√°lise LLM desativada neste modo"

        # FASE 8: AN√ÅLISE YARA COMPLETA (baseado no modo selecionado)
        if run_yara:
            logger.info("üîç Executando an√°lise YARA...")
            if is_csv:
                logger.warning("‚ö†Ô∏è Arquivos CSV n√£o suportam an√°lise YARA (sem payload). An√°lise apenas comportamental.")
                relatorio_yara_texto = "‚ö†Ô∏è An√°lise YARA n√£o aplic√°vel para arquivos CSV (sem payload bin√°rio)"
                relatorio_yara_resultado = {"total_deteccoes": 0, "arquivos_extraidos": 0}
            else:
                try:
                    relatorio_yara_resultado = executar_analise_yara_completa(arquivo_pcap)
                    relatorio_yara_texto = relatorio_yara_resultado.get(
                        "relatorio_texto", "‚ùå Relat√≥rio YARA n√£o dispon√≠vel"
                    )
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è An√°lise YARA falhou: {e}")
                    relatorio_yara_resultado = {"total_deteccoes": 0, "arquivos_extraidos": 0}
                    relatorio_yara_texto = "‚ùå An√°lise YARA n√£o dispon√≠vel"
        else:
            logger.info(f"‚è≠Ô∏è Modo '{analysis_mode}': Pulando an√°lise YARA")
            relatorio_yara_texto = f"‚ö†Ô∏è An√°lise YARA desativada (modo: {analysis_mode})"
            relatorio_yara_resultado = {"total_deteccoes": 0, "arquivos_extraidos": 0}
        
        # Extrair assinaturas detectadas pelo YARA para o painel
        malware_signatures = {}
        if relatorio_yara_resultado.get("deteccoes"):
            for deteccao in relatorio_yara_resultado["deteccoes"]:
                regra = deteccao.get("regra", "Desconhecido")
                # Limpar nome da regra (remover sufixos t√©cnicos se houver)
                familia = regra.replace("_", " ").strip()
                malware_signatures[familia] = malware_signatures.get(familia, 0) + 1
        
        # Atualizar score de malware com detec√ß√µes YARA
        total_deteccoes_yara = relatorio_yara_resultado.get("total_deteccoes", 0)
        if total_deteccoes_yara > 0:
            severidade_maxima = relatorio_yara_resultado.get("severidade_maxima", "baixa")
            
            # Adicionar pontos ao score baseado na severidade
            yara_score_adicional = 0
            if severidade_maxima == "critica":
                yara_score_adicional = 50  # Malware cr√≠tico = +50 pontos
                scoring_result["evidencias"].append(
                    f"CR√çTICO: {total_deteccoes_yara} detec√ß√µes YARA de severidade CR√çTICA"
                )
            elif severidade_maxima == "alta":
                yara_score_adicional = 35  # Malware alto = +35 pontos
                scoring_result["evidencias"].append(
                    f"ALTO: {total_deteccoes_yara} detec√ß√µes YARA de severidade ALTA"
                )
            elif severidade_maxima == "media":
                yara_score_adicional = 25  # Malware m√©dio = +25 pontos
                scoring_result["evidencias"].append(
                    f"M√âDIO: {total_deteccoes_yara} detec√ß√µes YARA de severidade M√âDIA"
                )
            else:
                yara_score_adicional = 15  # Malware baixo = +15 pontos
                scoring_result["evidencias"].append(
                    f"BAIXO: {total_deteccoes_yara} detec√ß√µes YARA"
                )
            
            # Atualizar score (m√°ximo 100)
            scoring_result["score"] = min(scoring_result["score"] + yara_score_adicional, 100)
            scoring_result["nivel_risco"] = get_risk_level(scoring_result["score"])

        # Adicionar contexto avan√ßado para o LLM (sem assinaturas)
        contexto_avancado = f"""
AN√ÅLISE DE SEGURAN√áA AVAN√áADA - Score: {scoring_result.get('score', 0)}/100 ({scoring_result.get('nivel_risco', 'M√çNIMO')})

RESUMO EXECUTIVO:
- Total de pacotes: {len(dados_pacotes)}
- Score de malware: {scoring_result.get('score', 0)}/100
- N√≠vel de risco: {scoring_result.get('nivel_risco', 'M√çNIMO')}

EVID√äNCIAS ENCONTRADAS:
{chr(10).join(f"‚Ä¢ {evidencia}" for evidencia in scoring_result.get('evidencias', []))}

THREAT INTELLIGENCE:
- IPs maliciosos: {len(iocs_e_dominios.get('malicious_ips', []))}
- Dom√≠nios suspeitos: {len(iocs_e_dominios.get('malicious_domains', []))}
- Regi√µes suspeitas: {len(iocs_e_dominios.get('suspicious_countries', []))}

AN√ÅLISE COMPORTAMENTAL:
- Beaconing detectado: {len(comportamento_temporal.get('beaconing_intervals', []))} padr√µes
- Burst patterns: {len(comportamento_temporal.get('burst_patterns', []))} eventos

AN√ÅLISE YARA:
{relatorio_yara_texto}

Por favor, analise estes dados considerando o contexto de seguran√ßa avan√ßado fornecido.
"""

        # FASE 9: AN√ÅLISE LLM H√çBRIDA (apenas se ativado)
        if run_llm:
            logger.info("ü§ñ Executando an√°lise h√≠brida com LLM...")
            try:
                analise_llm = analisar_com_llm_hibrido(
                    dados_formatados, relatorio_yara_texto, modelo, host=host, port=port
                )
            except Exception as e_llm:
                logger.error(f"Falha na an√°lise LLM: {e_llm}. Retornando erro.")
                raise Exception(f"Erro na an√°lise LLM: {e_llm}")  # Remover fallback
        else:
            logger.info(f"‚è≠Ô∏è Modo '{analysis_mode}': An√°lise LLM desativada")
            analise_llm = f"üìä MODO: {analysis_mode.upper()}\n\n{relatorio_yara_texto}"

        # FASE 10: RESULTADO FINAL COMBINADO
        total_deteccoes_yara = relatorio_yara_resultado.get("total_deteccoes", 0)
        arquivos_extraidos = relatorio_yara_resultado.get("arquivos_extraidos", 0)

        resumo = f"""
üìã AN√ÅLISE COMPLETA FINALIZADA
‚îú‚îÄ Pacotes analisados: {len(dados_pacotes)}
‚îú‚îÄ Score de malware: {scoring_result.get('score', 0)}/100 ({scoring_result.get('nivel_risco', 'M√çNIMO')})
‚îú‚îÄ IOCs encontrados: {len(iocs_e_dominios.get('malicious_ips', [])) + len(iocs_e_dominios.get('malicious_domains', []))}
‚îú‚îÄ Detec√ß√µes YARA: {total_deteccoes_yara}
‚îú‚îÄ Arquivos extra√≠dos: {arquivos_extraidos}
‚îî‚îÄ Modelo LLM: {modelo}
"""

        logger.info(
            f"‚úÖ An√°lise h√≠brida conclu√≠da: Score {scoring_result.get('score', 0)}/100 | {total_deteccoes_yara} detec√ß√µes YARA"
        )

        network_patterns = {
            "ddos_attacks": len(padroes_suspeitos.get("ddos_attacks", {})),
            "conexoes_multiplas": len(
                padroes_suspeitos.get("hosts_com_multiplas_conexoes", {})
            ),
            "port_scanning": len(padroes_suspeitos.get("port_scanning", {})),
            "trafego_alta_entropia": len(padroes_suspeitos.get("comunicacao_c2", [])),
        }

        return {
            "packet_count": len(dados_pacotes),
            "analysis_text": analise_llm,
            "summary": resumo,
            "raw_data": dados_formatados,
            "malware_score": scoring_result.get("score", 0),
            "risk_level": scoring_result.get("nivel_risco", "M√çNIMO"),
            "network_patterns": network_patterns,
            "malware_signatures": malware_signatures,  # Extra√≠do das detec√ß√µes YARA
            "temporal_analysis": {
                "beaconing_count": len(comportamento_temporal.get("beaconing_intervals", [])),
                "burst_count": len(comportamento_temporal.get("burst_patterns", [])),
                "periodic_patterns": len(
                    comportamento_temporal.get("periodic_communication", [])
                ),
            },
            "threat_intelligence": {
                "malicious_ips_count": len(iocs_e_dominios.get("malicious_ips", [])),
                "malicious_domains_count": len(iocs_e_dominios.get("malicious_domains", [])),
                "suspicious_countries_count": len(iocs_e_dominios.get("suspicious_countries", [])),
                "top_threats": iocs_e_dominios.get("malicious_ips", [])[:10],
            },
            "yara_detections": total_deteccoes_yara,
            "extracted_files": arquivos_extraidos,
            "yara_report": relatorio_yara_texto,
        }

    except Exception as e:
        logger.error(f"‚ùå Erro na an√°lise: {str(e)}")
        raise Exception(f"Erro na an√°lise avan√ßada: {str(e)}")


################################################################################
# 6. BLOCO DE TESTE LOCAL
################################################################################

if __name__ == "__main__":
    # Configura√ß√£o de logging para aparecer no console durante o teste
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Hack de path para permitir a execu√ß√£o local e encontrar os m√≥dulos
    # no diret√≥rio pai (como .utils e .yara_detector)
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(
            current_dir
        )  # Assumindo que .utils est√° em parent_dir
        sys.path.append(parent_dir)

        # Tentar re-importar com o novo path
        from utils import get_ollama_models as get_ollama_models_subprocess
        from yara_detector import executar_analise_yara_completa

        logger.info("M√≥dulos .utils e .yara_detector recarregados para teste local.")
    except ImportError as e:
        logger.warning(f"N√£o foi poss√≠vel carregar m√≥dulos locais para teste: {e}")
        # Manter os fallbacks definidos no in√≠cio do script

    print("\n--- Testando analisador PCAP (execu√ß√£o local) ---")
    try:
        status = get_ollama_status()
        if status["ok"]:
            print(f"‚úÖ Status Ollama: OK ({status['models']} modelos encontrados)")
            models = get_available_models()
            print(f"   Modelos dispon√≠veis: {models}")

            # Para testar, crie um arquivo 'dummy.pcap' ou aponte para um PCAP real
            TEST_PCAP = "exemplo.pcap"  # Mude isso
            if not os.path.exists(TEST_PCAP):
                print(
                    f"‚ö†Ô∏è  Arquivo de teste '{TEST_PCAP}' n√£o encontrado. Pulando teste de an√°lise."
                )
            else:
                print(f"\nüöÄ Iniciando an√°lise de '{TEST_PCAP}'...")
                resultado = analyze_pcap_with_llm(
                    TEST_PCAP, modelo=models[0] if models else "llama3"
                )
                print("\n--- RESUMO DA AN√ÅLISE ---")
                print(resultado["summary"])
                print("\n--- AN√ÅLISE DO LLM ---")
                print(resultado["analysis_text"])
                print("-------------------------")

        else:
            print(f"‚ùå Status Ollama: ERRO ({status['error']})")

    except Exception as e:
        print(f"‚ùå Erro no teste local: {e}")
